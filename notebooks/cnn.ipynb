{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload chaque module spécifié par %aimport\n",
    "%autoreload 1\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import src.constants as constants\n",
    "import src.filenameGenerator as fileNameGen\n",
    "import src.imageLoader as iLoader\n",
    "import src.tuning as tuning\n",
    "import src.runUtil as runUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : (140, 140, 3)\n",
      "gala_imgs shape : (4227, 140, 140, 3)\n",
      "gala_labels shape : (4227,)\n",
      "nb_spiral : 2185\n",
      "nb_smooth : 2042\n"
     ]
    }
   ],
   "source": [
    "%aimport src.imageLoader\n",
    "\n",
    "# Charge les images, leur étiquette et affiche des stats.\n",
    "\n",
    "gala_imgs, gala_labels = iLoader.load_processed_imgs(max_load=4227)\n",
    "\n",
    "gala_imgs = np.array(gala_imgs)\n",
    "gala_labels = np.array(gala_labels)\n",
    "\n",
    "INPUT_SHAPE = gala_imgs[0].shape\n",
    "\n",
    "print('input shape : ' + str(INPUT_SHAPE))\n",
    "\n",
    "print('gala_imgs shape : ' + str(gala_imgs.shape))\n",
    "print('gala_labels shape : ' + str(gala_labels.shape))\n",
    "\n",
    "nb_spiral = sum([ 1 if x == 'spiral' else 0 for x in np.nditer(gala_labels)])\n",
    "print('nb_spiral : ' + str(nb_spiral))\n",
    "nb_smooth = len(gala_labels) - nb_spiral\n",
    "print('nb_smooth : ' + str(nb_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encode les étiquettes\n",
    "gala_labels_2d = gala_labels.reshape(len(gala_labels), 1)\n",
    "\n",
    "oh_encoder = OneHotEncoder(sparse=False)\n",
    "gala_labels_oh = oh_encoder.fit_transform(gala_labels_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "baseline_25percent\n",
      "==================================\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_200 (Conv2D)          (None, 140, 140, 3)       84        \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 138, 138, 3)       84        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_100 (MaxPoolin (None, 69, 69, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 69, 69, 6)         168       \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 67, 67, 6)         330       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 33, 33, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 33, 33, 12)        660       \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 31, 31, 12)        1308      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 15, 15, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 15, 15, 24)        2616      \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 13, 13, 24)        5208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 6, 6, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 1730      \n",
      "=================================================================\n",
      "Total params: 12,188\n",
      "Trainable params: 12,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3381 samples, validate on 846 samples\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33995, saving model to /home/marc/Ecole/gti770/tp3/GTI770/models/cnn/baseline_25percent.h5\n",
      " - 13s - loss: 0.5036 - acc: 0.7507 - precision: 0.7507 - recall: 0.7507 - val_loss: 0.3400 - val_acc: 0.8582 - val_precision: 0.8582 - val_recall: 0.8582\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33995 to 0.33272, saving model to /home/marc/Ecole/gti770/tp3/GTI770/models/cnn/baseline_25percent.h5\n",
      " - 4s - loss: 0.2860 - acc: 0.8811 - precision: 0.8811 - recall: 0.8811 - val_loss: 0.3327 - val_acc: 0.8534 - val_precision: 0.8534 - val_recall: 0.8534\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33272 to 0.25885, saving model to /home/marc/Ecole/gti770/tp3/GTI770/models/cnn/baseline_25percent.h5\n",
      " - 4s - loss: 0.2321 - acc: 0.9080 - precision: 0.9080 - recall: 0.9080 - val_loss: 0.2588 - val_acc: 0.8924 - val_precision: 0.8924 - val_recall: 0.8924\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25885 to 0.24520, saving model to /home/marc/Ecole/gti770/tp3/GTI770/models/cnn/baseline_25percent.h5\n",
      " - 4s - loss: 0.2047 - acc: 0.9225 - precision: 0.9225 - recall: 0.9225 - val_loss: 0.2452 - val_acc: 0.8972 - val_precision: 0.8972 - val_recall: 0.8972\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24520\n",
      " - 4s - loss: 0.1758 - acc: 0.9317 - precision: 0.9317 - recall: 0.9317 - val_loss: 0.3184 - val_acc: 0.8700 - val_precision: 0.8700 - val_recall: 0.8700\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.24520 to 0.20895, saving model to /home/marc/Ecole/gti770/tp3/GTI770/models/cnn/baseline_25percent.h5\n",
      " - 4s - loss: 0.1512 - acc: 0.9423 - precision: 0.9423 - recall: 0.9423 - val_loss: 0.2089 - val_acc: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20895 to 0.19349, saving model to /home/marc/Ecole/gti770/tp3/GTI770/models/cnn/baseline_25percent.h5\n",
      " - 4s - loss: 0.1314 - acc: 0.9497 - precision: 0.9497 - recall: 0.9497 - val_loss: 0.1935 - val_acc: 0.9243 - val_precision: 0.9243 - val_recall: 0.9243\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19349\n",
      " - 4s - loss: 0.1152 - acc: 0.9539 - precision: 0.9539 - recall: 0.9539 - val_loss: 0.2062 - val_acc: 0.9338 - val_precision: 0.9338 - val_recall: 0.9338\n",
      "Epoch 9/50\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19349\n",
      " - 6s - loss: 0.1053 - acc: 0.9607 - precision: 0.9607 - recall: 0.9607 - val_loss: 0.2606 - val_acc: 0.9326 - val_precision: 0.9326 - val_recall: 0.9326\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>baseline_25percent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time (seconds)</th>\n",
       "      <td>68.0494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_epoch</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_loss</th>\n",
       "      <td>0.131413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_val_loss</th>\n",
       "      <td>0.193495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_accuracy</th>\n",
       "      <td>0.949719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_val_accuracy</th>\n",
       "      <td>0.92435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_f1</th>\n",
       "      <td>0.949719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_val_f1</th>\n",
       "      <td>0.92435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "run_name              baseline_25percent\n",
       "config                              None\n",
       "train_time (seconds)             68.0494\n",
       "best_epoch                             7\n",
       "best_loss                       0.131413\n",
       "best_val_loss                   0.193495\n",
       "best_accuracy                   0.949719\n",
       "best_val_accuracy                0.92435\n",
       "best_f1                         0.949719\n",
       "best_val_f1                      0.92435"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%aimport src.constants\n",
    "%aimport src.filenameGenerator\n",
    "%aimport src.tuning\n",
    "%aimport src.runUtil\n",
    "\n",
    "def create_cnn_model(config=None):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (3, 3), padding='same', activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(3, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(6, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(6, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(12, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(12, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    if config is None or 'layers' not in config or config['layers'] == 'more':\n",
    "        model.add(Conv2D(24, (3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(24, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "    if config is not None and 'layers' in config and config['layers'] == 'more':\n",
    "        model.add(Conv2D(48, (3, 3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(48, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    if config is not None and 'learning_rate' in config:\n",
    "        optimizer = RMSprop(lr=config['learning_rate'])\n",
    "    else:\n",
    "        optimizer = RMSprop()\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            Precision(name='precision'), \n",
    "            Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def cnn_train(run_name, config=None):\n",
    "    \"\"\"\n",
    "    config:\n",
    "        batch_size\n",
    "    \"\"\"\n",
    "    \n",
    "    print('==================================')\n",
    "    print(run_name)\n",
    "    print('==================================')\n",
    "\n",
    "    model_save_path = os.path.join(\n",
    "        constants.PROJECT_ROOT_PATH,\n",
    "        constants.CNN_MODELS_PATH,\n",
    "        run_name + '.h5'\n",
    "    )\n",
    "    \n",
    "    model = create_cnn_model(config)\n",
    "    model.summary()\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.CNN_LOGS_PATH + run_name)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True, verbose=1)\n",
    "    model_ckeckpt = ModelCheckpoint(filepath=model_save_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    callbacks = [\n",
    "        tk_board, \n",
    "        early_stop, \n",
    "        model_ckeckpt\n",
    "    ]\n",
    "    \n",
    "    # Fit le model\n",
    "    start_train_time = time.perf_counter()\n",
    "    \n",
    "    if config is not None and 'batch_size' in config:\n",
    "        history = model.fit(\n",
    "            x=gala_imgs, y=gala_labels_oh, epochs=50, shuffle=True,\n",
    "            batch_size=config['batch_size'], validation_split=0.2, \n",
    "            verbose=2, callbacks=callbacks\n",
    "        )\n",
    "    else: \n",
    "        history = model.fit(\n",
    "            x=gala_imgs, y=gala_labels_oh, epochs=50, shuffle=True,\n",
    "            validation_split=0.2, verbose=2, callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "    train_time = time.perf_counter() - start_train_time\n",
    "    \n",
    "    runUtil.save_history(history.history, run_name)\n",
    "    \n",
    "    # Agrège les résultats\n",
    "    run_results = OrderedDict([\n",
    "        ('run_name', run_name),\n",
    "        ('config', config),\n",
    "        ('train_time (seconds)', train_time)\n",
    "    ])\n",
    "    \n",
    "    hist_resume = runUtil.resume_history(history.history)\n",
    "    run_results.update(hist_resume)\n",
    "    \n",
    "    runUtil.save_run_results(run_results, run_name)\n",
    "    \n",
    "    if config is not None:\n",
    "        runUtil.save_config(config, run_name)\n",
    "    \n",
    "    return run_results\n",
    "\n",
    "\n",
    "runs_results = []\n",
    "\n",
    "run_results_baseline = cnn_train(run_name='baseline_25percent')\n",
    "runs_results.append(run_results_baseline)\n",
    "\n",
    "\"\"\"\n",
    "# Baseline\n",
    "run_results_baseline = cnn_train(run_name='baseline')\n",
    "runs_results.append(run_results_baseline)\n",
    "\n",
    "# Higher batch size\n",
    "run_results_higher_batch = cnn_train(\n",
    "    run_name='higher_batch_size',\n",
    "    config={\n",
    "        'batch_size': 150\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_higher_batch)\n",
    "\n",
    "# Lower batch size\n",
    "run_results_lower_batch = cnn_train(\n",
    "    run_name='lower_batch_size',\n",
    "    config={\n",
    "        'batch_size': 10\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_lower_batch)\n",
    "\n",
    "# Less convolutional layers\n",
    "run_results_less_conv = cnn_train(\n",
    "    run_name='less_conv_layers',\n",
    "    config={\n",
    "        'layers': 'less'\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_less_conv)\n",
    "\n",
    "# More convolutional layers\n",
    "run_results_more_conv = cnn_train(\n",
    "    run_name='more_conv_layers',\n",
    "    config={\n",
    "        'layers': 'more'\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_more_conv)\n",
    "\n",
    "# Lower learning rate\n",
    "run_results_lower_lr = cnn_train(\n",
    "    run_name='lower_learning_rate6',\n",
    "    config={\n",
    "        'learning_rate': 0.0001\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_lower_lr)\n",
    "\n",
    "# Higher learning rate\n",
    "run_results_higher_lr = cnn_train(\n",
    "    run_name='higher_learning_rate',\n",
    "    config={\n",
    "        'learning_rate': 0.01\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_higher_lr)\n",
    "\n",
    "# 100 epochs\n",
    "run_results_100_epoch = cnn_train(\n",
    "    run_name='baseline_100epoch'\n",
    ")\n",
    "runs_results.append(run_results_100_epoch)\n",
    "\n",
    "# Way higher batch size\n",
    "run_results_way_higher_batch = cnn_train(\n",
    "    run_name='way_higher_batch_size',\n",
    "    config={\n",
    "        'batch_size': 250\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_way_higher_batch)\n",
    "\n",
    "# Way way higher batch size\n",
    "run_results_way_way_higher_batch = cnn_train(\n",
    "    run_name='way_way_higher_batch_size',\n",
    "    config={\n",
    "        'batch_size': 350\n",
    "    }\n",
    ")\n",
    "runs_results.append(run_results_way_way_higher_batch)\n",
    "\"\"\"\n",
    "\n",
    "display(pd.DataFrame(runs_results).transpose())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
