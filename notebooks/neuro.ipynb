{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplt\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.constants as constants\n",
    "import src.filenameGenerator as fileNameGen\n",
    "import src.imageLoader as iLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Lecture fichiers CSV\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# Le fichier CSV contenant les données galaxies\n",
    "csv_vectors = 'data/processed/galaxy_feature_vectors.csv'\n",
    "\n",
    "# Recupere les données galaxies (saute la premiere et derniere colonne --> ID galaxie)\n",
    "X_galaxy = pd.read_csv(csv_vectors, header=None).values[:,1:-1]\n",
    "\n",
    "# Recupere la colonne indiquant si c'est une galaxie spiral (1) ou smooth (0)\n",
    "Y_galaxy = pd.read_csv(csv_vectors, header=None).values[:,-1:].astype(int).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Normalisation\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_galaxy = scaler.fit_transform(X_galaxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# One Hot encode les étiquettes\n",
    "\n",
    "gala_labels_2d = Y_galaxy.reshape(len(Y_galaxy))\n",
    "\n",
    "oh_encoder = OneHotEncoder(sparse=False)\n",
    "gala_labels_2d = gala_labels_2d.reshape(-1,1)\n",
    "gala_labels_oh = oh_encoder.fit_transform(gala_labels_2d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeNN(x, y, name, lr, epoch, layers):\n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + name)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(layers[0], input_shape=(x.shape[1],), activation='relu'))\n",
    "    for index in range(1, len(layers)-1):\n",
    "        model.add(keras.layers.Dense(layers[index], activation='relu'))\n",
    "    model.add(keras.layers.Dense(layers[len(layers)-1], activation='softmax'))\n",
    "    \n",
    "    optimizer = keras.optimizers.RMSprop(lr=lr)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            tf.keras.metrics.Accuracy(), \n",
    "            tf.keras.metrics.Precision(name='precision'), \n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    start_train_time = time.perf_counter()\n",
    "    history = model.fit(x=x, y=y, batch_size=100, epochs=epoch, shuffle=True, validation_split=0.2, callbacks=[tk_board])\n",
    "    train_time = time.perf_counter() - start_train_time\n",
    "\n",
    "    history = history.history\n",
    "    index = len(history['precision']) -1\n",
    "    precision = history['precision'][index]\n",
    "    recall = history['recall'][index]\n",
    "    val_precision = history['val_precision'][index]\n",
    "    val_recall = history['val_recall'][index]\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "    accuracy = history['accuracy'][index]\n",
    "    val_accuracy = history['val_accuracy'][index]\n",
    "\n",
    "    run_results = OrderedDict([\n",
    "        ('run_name', name),\n",
    "        ('train_time (seconds)', train_time),\n",
    "        ('learning rate', lr),\n",
    "        ('epoch', epoch),\n",
    "        ('accuracy', accuracy),\n",
    "        ('val_accuracy', val_accuracy),\n",
    "        ('f1', f1),\n",
    "        ('val_f1', val_f1)\n",
    "    ])\n",
    "\n",
    "    for index in range(0, len(layers)):\n",
    "        run_results['layer: ' + str(index)] = layers[index]\n",
    "\n",
    "    return run_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "x = X_galaxy\n",
    "y = gala_labels_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jonathan\\Anaconda3\\envs\\gti770\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Jonathan\\Anaconda3\\envs\\gti770\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 0s 35us/sample - loss: 0.1826 - accuracy: 4.8056e-04 - precision: 0.9326 - recall: 0.9326 - val_loss: 0.1646 - val_accuracy: 4.4352e-04 - val_precision: 0.9474 - val_recall: 0.9474\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.1272 - accuracy: 0.0017 - precision: 0.9545 - recall: 0.9545 - val_loss: 0.1867 - val_accuracy: 0.0031 - val_precision: 0.9344 - val_recall: 0.9344\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.1159 - accuracy: 0.0023 - precision: 0.9582 - recall: 0.9582 - val_loss: 0.1158 - val_accuracy: 0.0013 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.1071 - accuracy: 0.0044 - precision: 0.9611 - recall: 0.9611 - val_loss: 0.1163 - val_accuracy: 0.0038 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0962 - accuracy: 0.0126 - precision: 0.9655 - recall: 0.9655 - val_loss: 0.1179 - val_accuracy: 0.0022 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0934 - accuracy: 0.0150 - precision: 0.9665 - recall: 0.9665 - val_loss: 0.1329 - val_accuracy: 0.0204 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0923 - accuracy: 0.0243 - precision: 0.9681 - recall: 0.9681 - val_loss: 0.1281 - val_accuracy: 0.0235 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0836 - accuracy: 0.0272 - precision: 0.9697 - recall: 0.9697 - val_loss: 0.1282 - val_accuracy: 0.0333 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0830 - accuracy: 0.0337 - precision: 0.9714 - recall: 0.9714 - val_loss: 0.1534 - val_accuracy: 0.0881 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0793 - accuracy: 0.0467 - precision: 0.9731 - recall: 0.9731 - val_loss: 0.1324 - val_accuracy: 0.0395 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0754 - accuracy: 0.0493 - precision: 0.9743 - recall: 0.9743 - val_loss: 0.1217 - val_accuracy: 0.0504 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0742 - accuracy: 0.0807 - precision: 0.9739 - recall: 0.9739 - val_loss: 0.1399 - val_accuracy: 0.0553 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0666 - accuracy: 0.0939 - precision: 0.9769 - recall: 0.9769 - val_loss: 0.1275 - val_accuracy: 0.0614 - val_precision: 0.9645 - val_recall: 0.9645\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0668 - accuracy: 0.1120 - precision: 0.9772 - recall: 0.9772 - val_loss: 0.1653 - val_accuracy: 0.0797 - val_precision: 0.9542 - val_recall: 0.9542\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0609 - accuracy: 0.1277 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.1401 - val_accuracy: 0.0788 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0629 - accuracy: 0.1417 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1624 - val_accuracy: 0.1106 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0587 - accuracy: 0.1600 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.1531 - val_accuracy: 0.1298 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0566 - accuracy: 0.1862 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.1511 - val_accuracy: 0.1663 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0554 - accuracy: 0.1933 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.1878 - val_accuracy: 0.2290 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0584 - accuracy: 0.2267 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.1840 - val_accuracy: 0.2213 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0563 - accuracy: 0.2331 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.1703 - val_accuracy: 0.2213 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0510 - accuracy: 0.2415 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.1863 - val_accuracy: 0.2456 - val_precision: 0.9657 - val_recall: 0.9657\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0503 - accuracy: 0.2531 - precision: 0.9863 - recall: 0.9863 - val_loss: 0.1969 - val_accuracy: 0.2677 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0642 - accuracy: 0.2561 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.1850 - val_accuracy: 0.2467 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0511 - accuracy: 0.2565 - precision: 0.9859 - recall: 0.9859 - val_loss: 0.2405 - val_accuracy: 0.3046 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0478 - accuracy: 0.2758 - precision: 0.9865 - recall: 0.9865 - val_loss: 0.2060 - val_accuracy: 0.2951 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0509 - accuracy: 0.2851 - precision: 0.9859 - recall: 0.9859 - val_loss: 0.2044 - val_accuracy: 0.2954 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0401 - accuracy: 0.2898 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.2197 - val_accuracy: 0.2809 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0415 - accuracy: 0.3166 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.2251 - val_accuracy: 0.3210 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0511 - accuracy: 0.3206 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.2274 - val_accuracy: 0.3285 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0466 - accuracy: 0.3226 - precision: 0.9879 - recall: 0.9879 - val_loss: 0.2087 - val_accuracy: 0.3097 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0511 - accuracy: 0.3256 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.2073 - val_accuracy: 0.3046 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0570 - accuracy: 0.3348 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2383 - val_accuracy: 0.3387 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0484 - accuracy: 0.3487 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2831 - val_accuracy: 0.3412 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0405 - accuracy: 0.3551 - precision: 0.9898 - recall: 0.9898 - val_loss: 0.2467 - val_accuracy: 0.3437 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0475 - accuracy: 0.3708 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2620 - val_accuracy: 0.3369 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0426 - accuracy: 0.3666 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2524 - val_accuracy: 0.3808 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0455 - accuracy: 0.3772 - precision: 0.9893 - recall: 0.9893 - val_loss: 0.3389 - val_accuracy: 0.3938 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 39/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0411 - accuracy: 0.3779 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.2806 - val_accuracy: 0.3464 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0385 - accuracy: 0.3818 - precision: 0.9902 - recall: 0.9902 - val_loss: 0.2594 - val_accuracy: 0.3800 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0600 - accuracy: 0.4010 - precision: 0.9893 - recall: 0.9893 - val_loss: 0.2881 - val_accuracy: 0.3941 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0356 - accuracy: 0.4037 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.2564 - val_accuracy: 0.4026 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0474 - accuracy: 0.3968 - precision: 0.9905 - recall: 0.9905 - val_loss: 0.2784 - val_accuracy: 0.3953 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0372 - accuracy: 0.3927 - precision: 0.9919 - recall: 0.9919 - val_loss: 0.2868 - val_accuracy: 0.3862 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0392 - accuracy: 0.3985 - precision: 0.9915 - recall: 0.9915 - val_loss: 0.3901 - val_accuracy: 0.4011 - val_precision: 0.9524 - val_recall: 0.9524\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0482 - accuracy: 0.4159 - precision: 0.9913 - recall: 0.9913 - val_loss: 0.2721 - val_accuracy: 0.4119 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0383 - accuracy: 0.4282 - precision: 0.9921 - recall: 0.9921 - val_loss: 0.2798 - val_accuracy: 0.4064 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0351 - accuracy: 0.4312 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.2569 - val_accuracy: 0.4020 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0360 - accuracy: 0.4163 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.2782 - val_accuracy: 0.4181 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0333 - accuracy: 0.4387 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.3187 - val_accuracy: 0.4431 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0389 - accuracy: 0.4387 - precision: 0.9928 - recall: 0.9928 - val_loss: 0.2986 - val_accuracy: 0.4271 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0536 - accuracy: 0.4545 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.3315 - val_accuracy: 0.4787 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0376 - accuracy: 0.4684 - precision: 0.9928 - recall: 0.9928 - val_loss: 0.3184 - val_accuracy: 0.4608 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0279 - accuracy: 0.4655 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.3042 - val_accuracy: 0.4741 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0333 - accuracy: 0.4834 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.3212 - val_accuracy: 0.4348 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0338 - accuracy: 0.4737 - precision: 0.9933 - recall: 0.9933 - val_loss: 0.3257 - val_accuracy: 0.4765 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0303 - accuracy: 0.4776 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.3151 - val_accuracy: 0.4718 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0329 - accuracy: 0.4936 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.3159 - val_accuracy: 0.4827 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0343 - accuracy: 0.4884 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.3069 - val_accuracy: 0.4902 - val_precision: 0.9654 - val_recall: 0.9654\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0417 - accuracy: 0.4876 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.3366 - val_accuracy: 0.4891 - val_precision: 0.9592 - val_recall: 0.9592\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Baseline\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x, y, \"NN/BaseLine\",0.005,60, [100,100,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 38,402\n",
      "Trainable params: 38,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 1s 43us/sample - loss: 0.2129 - accuracy: 0.0014 - precision: 0.9265 - recall: 0.9265 - val_loss: 0.2279 - val_accuracy: 0.0037 - val_precision: 0.9293 - val_recall: 0.9293\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.1374 - accuracy: 0.0023 - precision: 0.9510 - recall: 0.9510 - val_loss: 0.1885 - val_accuracy: 0.0272 - val_precision: 0.9468 - val_recall: 0.9468\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.1210 - accuracy: 0.0083 - precision: 0.9593 - recall: 0.9593 - val_loss: 0.1309 - val_accuracy: 0.0010 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.1139 - accuracy: 0.0073 - precision: 0.9617 - recall: 0.9617 - val_loss: 0.1339 - val_accuracy: 0.0041 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.1061 - accuracy: 0.0149 - precision: 0.9640 - recall: 0.9640 - val_loss: 0.1794 - val_accuracy: 0.0288 - val_precision: 0.9509 - val_recall: 0.9509\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.1038 - accuracy: 0.0223 - precision: 0.9674 - recall: 0.9674 - val_loss: 0.1664 - val_accuracy: 0.0124 - val_precision: 0.9512 - val_recall: 0.9512\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0955 - accuracy: 0.0281 - precision: 0.9664 - recall: 0.9664 - val_loss: 0.1497 - val_accuracy: 0.0074 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0924 - accuracy: 0.0469 - precision: 0.9683 - recall: 0.9683 - val_loss: 0.1199 - val_accuracy: 0.0137 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0912 - accuracy: 0.0351 - precision: 0.9704 - recall: 0.9704 - val_loss: 0.1735 - val_accuracy: 0.0679 - val_precision: 0.9536 - val_recall: 0.9536\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0878 - accuracy: 0.0538 - precision: 0.9709 - recall: 0.9709 - val_loss: 0.2091 - val_accuracy: 0.0979 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0842 - accuracy: 0.0758 - precision: 0.9730 - recall: 0.9730 - val_loss: 0.1366 - val_accuracy: 0.0569 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0807 - accuracy: 0.0959 - precision: 0.9715 - recall: 0.9715 - val_loss: 0.1851 - val_accuracy: 0.2130 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0827 - accuracy: 0.1109 - precision: 0.9734 - recall: 0.9734 - val_loss: 0.1574 - val_accuracy: 0.0883 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0741 - accuracy: 0.1505 - precision: 0.9759 - recall: 0.9759 - val_loss: 0.2052 - val_accuracy: 0.2555 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0725 - accuracy: 0.1807 - precision: 0.9751 - recall: 0.9751 - val_loss: 0.1724 - val_accuracy: 0.1363 - val_precision: 0.9654 - val_recall: 0.9654\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 0s 23us/sample - loss: 0.0721 - accuracy: 0.2081 - precision: 0.9762 - recall: 0.9762 - val_loss: 0.1598 - val_accuracy: 0.1953 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0737 - accuracy: 0.2617 - precision: 0.9773 - recall: 0.9773 - val_loss: 0.1945 - val_accuracy: 0.2297 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0665 - accuracy: 0.2842 - precision: 0.9769 - recall: 0.9769 - val_loss: 0.1856 - val_accuracy: 0.3003 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0716 - accuracy: 0.3190 - precision: 0.9779 - recall: 0.9779 - val_loss: 0.1542 - val_accuracy: 0.2135 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0682 - accuracy: 0.2750 - precision: 0.9787 - recall: 0.9787 - val_loss: 0.2026 - val_accuracy: 0.3551 - val_precision: 0.9654 - val_recall: 0.9654\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0643 - accuracy: 0.3354 - precision: 0.9792 - recall: 0.9792 - val_loss: 0.1464 - val_accuracy: 0.2343 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 0s 23us/sample - loss: 0.0679 - accuracy: 0.4494 - precision: 0.9792 - recall: 0.9792 - val_loss: 0.1964 - val_accuracy: 0.4543 - val_precision: 0.9657 - val_recall: 0.9657\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0637 - accuracy: 0.3756 - precision: 0.9785 - recall: 0.9785 - val_loss: 0.2419 - val_accuracy: 0.4423 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0724 - accuracy: 0.4355 - precision: 0.9802 - recall: 0.9802 - val_loss: 0.2080 - val_accuracy: 0.4749 - val_precision: 0.9663 - val_recall: 0.9663\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 0s 24us/sample - loss: 0.0594 - accuracy: 0.4423 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.1806 - val_accuracy: 0.3718 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 0s 26us/sample - loss: 0.0631 - accuracy: 0.4533 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.2687 - val_accuracy: 0.5503 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 0s 26us/sample - loss: 0.0683 - accuracy: 0.4743 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.2540 - val_accuracy: 0.5235 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 0s 26us/sample - loss: 0.0658 - accuracy: 0.5139 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.2289 - val_accuracy: 0.5708 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 0s 25us/sample - loss: 0.0654 - accuracy: 0.5801 - precision: 0.9826 - recall: 0.9826 - val_loss: 0.2326 - val_accuracy: 0.4789 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 0s 23us/sample - loss: 0.0641 - accuracy: 0.5441 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.2117 - val_accuracy: 0.5285 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0661 - accuracy: 0.5366 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.2221 - val_accuracy: 0.5245 - val_precision: 0.9633 - val_recall: 0.9633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0615 - accuracy: 0.5368 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.2494 - val_accuracy: 0.6066 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0624 - accuracy: 0.5757 - precision: 0.9838 - recall: 0.9838 - val_loss: 0.2460 - val_accuracy: 0.4559 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0616 - accuracy: 0.5502 - precision: 0.9825 - recall: 0.9825 - val_loss: 0.2267 - val_accuracy: 0.4939 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0570 - accuracy: 0.5511 - precision: 0.9842 - recall: 0.9842 - val_loss: 0.2894 - val_accuracy: 0.5911 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0621 - accuracy: 0.6296 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.2457 - val_accuracy: 0.5235 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0852 - accuracy: 0.6357 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.2788 - val_accuracy: 0.5444 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0675 - accuracy: 0.6075 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.2952 - val_accuracy: 0.6263 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 39/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0590 - accuracy: 0.5943 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.2860 - val_accuracy: 0.5627 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0594 - accuracy: 0.5688 - precision: 0.9851 - recall: 0.9851 - val_loss: 0.2882 - val_accuracy: 0.5791 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0628 - accuracy: 0.6102 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.3326 - val_accuracy: 0.6681 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0675 - accuracy: 0.6157 - precision: 0.9855 - recall: 0.9855 - val_loss: 0.3052 - val_accuracy: 0.5886 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0584 - accuracy: 0.6200 - precision: 0.9856 - recall: 0.9856 - val_loss: 0.2461 - val_accuracy: 0.5446 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0673 - accuracy: 0.6100 - precision: 0.9862 - recall: 0.9862 - val_loss: 0.2951 - val_accuracy: 0.6270 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0586 - accuracy: 0.5982 - precision: 0.9873 - recall: 0.9873 - val_loss: 0.3362 - val_accuracy: 0.6165 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0567 - accuracy: 0.6463 - precision: 0.9868 - recall: 0.9868 - val_loss: 0.3154 - val_accuracy: 0.5744 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0573 - accuracy: 0.6174 - precision: 0.9858 - recall: 0.9858 - val_loss: 0.3118 - val_accuracy: 0.6378 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0543 - accuracy: 0.6494 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.2527 - val_accuracy: 0.5637 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.1149 - accuracy: 0.6183 - precision: 0.9801 - recall: 0.9801 - val_loss: 0.2368 - val_accuracy: 0.4861 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0913 - accuracy: 0.6001 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.3108 - val_accuracy: 0.7357 - val_precision: 0.9648 - val_recall: 0.9648\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0685 - accuracy: 0.6295 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.3255 - val_accuracy: 0.7027 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0676 - accuracy: 0.6556 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2602 - val_accuracy: 0.5760 - val_precision: 0.9465 - val_recall: 0.9465\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0587 - accuracy: 0.6843 - precision: 0.9875 - recall: 0.9875 - val_loss: 0.2888 - val_accuracy: 0.5943 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0694 - accuracy: 0.7037 - precision: 0.9860 - recall: 0.9860 - val_loss: 0.3581 - val_accuracy: 0.7571 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0609 - accuracy: 0.7255 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.2873 - val_accuracy: 0.6421 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0638 - accuracy: 0.7105 - precision: 0.9884 - recall: 0.9884 - val_loss: 0.2604 - val_accuracy: 0.5889 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0733 - accuracy: 0.7244 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.3165 - val_accuracy: 0.6635 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0666 - accuracy: 0.7010 - precision: 0.9879 - recall: 0.9879 - val_loss: 0.3338 - val_accuracy: 0.6691 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0651 - accuracy: 0.7035 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.3860 - val_accuracy: 0.7645 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0706 - accuracy: 0.7783 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.4029 - val_accuracy: 0.7636 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 8,102\n",
      "Trainable params: 8,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 0s 33us/sample - loss: 0.1849 - accuracy: 4.8056e-04 - precision: 0.9346 - recall: 0.9346 - val_loss: 0.1454 - val_accuracy: 2.9568e-04 - val_precision: 0.9506 - val_recall: 0.9506\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.1325 - accuracy: 8.1325e-04 - precision: 0.9543 - recall: 0.9543 - val_loss: 0.1300 - val_accuracy: 4.4352e-04 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.1191 - accuracy: 0.0016 - precision: 0.9593 - recall: 0.9593 - val_loss: 0.1516 - val_accuracy: 0.0015 - val_precision: 0.9512 - val_recall: 0.9512\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.1133 - accuracy: 0.0028 - precision: 0.9609 - recall: 0.9609 - val_loss: 0.1369 - val_accuracy: 2.9568e-04 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.1084 - accuracy: 0.0029 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.1527 - val_accuracy: 0.0025 - val_precision: 0.9503 - val_recall: 0.9503\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.1049 - accuracy: 0.0052 - precision: 0.9654 - recall: 0.9654 - val_loss: 0.1975 - val_accuracy: 0.0080 - val_precision: 0.9352 - val_recall: 0.9352\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0994 - accuracy: 0.0043 - precision: 0.9671 - recall: 0.9671 - val_loss: 0.1272 - val_accuracy: 0.0037 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0987 - accuracy: 0.0084 - precision: 0.9667 - recall: 0.9667 - val_loss: 0.1368 - val_accuracy: 0.0077 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0887 - accuracy: 0.0098 - precision: 0.9695 - recall: 0.9695 - val_loss: 0.3040 - val_accuracy: 0.0223 - val_precision: 0.9095 - val_recall: 0.9095\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0888 - accuracy: 0.0113 - precision: 0.9706 - recall: 0.9706 - val_loss: 0.1504 - val_accuracy: 0.0123 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0864 - accuracy: 0.0159 - precision: 0.9708 - recall: 0.9708 - val_loss: 0.1546 - val_accuracy: 0.0155 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0838 - accuracy: 0.0179 - precision: 0.9729 - recall: 0.9729 - val_loss: 0.1299 - val_accuracy: 0.0186 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0834 - accuracy: 0.0202 - precision: 0.9724 - recall: 0.9724 - val_loss: 0.1359 - val_accuracy: 0.0226 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0799 - accuracy: 0.0243 - precision: 0.9745 - recall: 0.9745 - val_loss: 0.1656 - val_accuracy: 0.0384 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0769 - accuracy: 0.0338 - precision: 0.9738 - recall: 0.9738 - val_loss: 0.1393 - val_accuracy: 0.0259 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0726 - accuracy: 0.0277 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.1449 - val_accuracy: 0.0489 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0743 - accuracy: 0.0379 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.1393 - val_accuracy: 0.0339 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0711 - accuracy: 0.0406 - precision: 0.9777 - recall: 0.9777 - val_loss: 0.1463 - val_accuracy: 0.0370 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0693 - accuracy: 0.0479 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1786 - val_accuracy: 0.0464 - val_precision: 0.9509 - val_recall: 0.9509\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0663 - accuracy: 0.0486 - precision: 0.9776 - recall: 0.9776 - val_loss: 0.1669 - val_accuracy: 0.0467 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0646 - accuracy: 0.0540 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1567 - val_accuracy: 0.0636 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0656 - accuracy: 0.0622 - precision: 0.9795 - recall: 0.9795 - val_loss: 0.1552 - val_accuracy: 0.0685 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0648 - accuracy: 0.0692 - precision: 0.9787 - recall: 0.9787 - val_loss: 0.1683 - val_accuracy: 0.0628 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0634 - accuracy: 0.0736 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.1512 - val_accuracy: 0.0835 - val_precision: 0.9654 - val_recall: 0.9654\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0593 - accuracy: 0.0812 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.2022 - val_accuracy: 0.0779 - val_precision: 0.9512 - val_recall: 0.9512\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0634 - accuracy: 0.0775 - precision: 0.9799 - recall: 0.9799 - val_loss: 0.1554 - val_accuracy: 0.0800 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0660 - accuracy: 0.0866 - precision: 0.9817 - recall: 0.9817 - val_loss: 0.1653 - val_accuracy: 0.0982 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0576 - accuracy: 0.0958 - precision: 0.9819 - recall: 0.9819 - val_loss: 0.1821 - val_accuracy: 0.1232 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0628 - accuracy: 0.1054 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.2233 - val_accuracy: 0.1166 - val_precision: 0.9518 - val_recall: 0.9518\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0573 - accuracy: 0.1000 - precision: 0.9827 - recall: 0.9827 - val_loss: 0.1674 - val_accuracy: 0.0917 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0568 - accuracy: 0.1120 - precision: 0.9833 - recall: 0.9833 - val_loss: 0.2068 - val_accuracy: 0.1372 - val_precision: 0.9533 - val_recall: 0.9533\n",
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0562 - accuracy: 0.1148 - precision: 0.9838 - recall: 0.9838 - val_loss: 0.1774 - val_accuracy: 0.1165 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0535 - accuracy: 0.1224 - precision: 0.9836 - recall: 0.9836 - val_loss: 0.1727 - val_accuracy: 0.1212 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0532 - accuracy: 0.1231 - precision: 0.9839 - recall: 0.9839 - val_loss: 0.1734 - val_accuracy: 0.1054 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0496 - accuracy: 0.1278 - precision: 0.9844 - recall: 0.9844 - val_loss: 0.1821 - val_accuracy: 0.1257 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0484 - accuracy: 0.1402 - precision: 0.9848 - recall: 0.9848 - val_loss: 0.1658 - val_accuracy: 0.1274 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0473 - accuracy: 0.1471 - precision: 0.9859 - recall: 0.9859 - val_loss: 0.1699 - val_accuracy: 0.1328 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0453 - accuracy: 0.1474 - precision: 0.9858 - recall: 0.9858 - val_loss: 0.1940 - val_accuracy: 0.1611 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0514 - accuracy: 0.1579 - precision: 0.9853 - recall: 0.9853 - val_loss: 0.2078 - val_accuracy: 0.1674 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0501 - accuracy: 0.1635 - precision: 0.9866 - recall: 0.9866 - val_loss: 0.2110 - val_accuracy: 0.1875 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0486 - accuracy: 0.1746 - precision: 0.9853 - recall: 0.9853 - val_loss: 0.1865 - val_accuracy: 0.1616 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0464 - accuracy: 0.1757 - precision: 0.9868 - recall: 0.9868 - val_loss: 0.1907 - val_accuracy: 0.1731 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0476 - accuracy: 0.1742 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.2194 - val_accuracy: 0.1580 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0459 - accuracy: 0.1809 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.2159 - val_accuracy: 0.1682 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0429 - accuracy: 0.1941 - precision: 0.9876 - recall: 0.9876 - val_loss: 0.1965 - val_accuracy: 0.2077 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0454 - accuracy: 0.1897 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.1866 - val_accuracy: 0.1829 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0442 - accuracy: 0.1988 - precision: 0.9868 - recall: 0.9868 - val_loss: 0.2292 - val_accuracy: 0.2206 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0382 - accuracy: 0.2071 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.2188 - val_accuracy: 0.2000 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0441 - accuracy: 0.2119 - precision: 0.9892 - recall: 0.9892 - val_loss: 0.2550 - val_accuracy: 0.2200 - val_precision: 0.9465 - val_recall: 0.9465\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0431 - accuracy: 0.2201 - precision: 0.9878 - recall: 0.9878 - val_loss: 0.2244 - val_accuracy: 0.2240 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0428 - accuracy: 0.2189 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.3058 - val_accuracy: 0.2229 - val_precision: 0.9486 - val_recall: 0.9486\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0463 - accuracy: 0.2293 - precision: 0.9881 - recall: 0.9881 - val_loss: 0.2213 - val_accuracy: 0.2431 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0400 - accuracy: 0.2279 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2314 - val_accuracy: 0.2504 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0433 - accuracy: 0.2360 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.1966 - val_accuracy: 0.2296 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0407 - accuracy: 0.2385 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2380 - val_accuracy: 0.2386 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0390 - accuracy: 0.2500 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.2192 - val_accuracy: 0.2450 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0385 - accuracy: 0.2537 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2110 - val_accuracy: 0.2244 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0389 - accuracy: 0.2571 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2146 - val_accuracy: 0.2426 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0419 - accuracy: 0.2597 - precision: 0.9892 - recall: 0.9892 - val_loss: 0.2478 - val_accuracy: 0.2439 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0394 - accuracy: 0.2633 - precision: 0.9895 - recall: 0.9895 - val_loss: 0.2688 - val_accuracy: 0.2661 - val_precision: 0.9568 - val_recall: 0.9568\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Couches\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x, y, \"NN/CouchePlus\",0.005,60, [100, 100, 100, 100,2]))\n",
    "results.append(executeNN(x, y, \"NN/CoucheMoins\",0.005,60, [100,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               39500     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 291,002\n",
      "Trainable params: 291,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 1s 73us/sample - loss: 0.2920 - accuracy: 0.0113 - precision: 0.9209 - recall: 0.9209 - val_loss: 0.1615 - val_accuracy: 0.0089 - val_precision: 0.9459 - val_recall: 0.9459\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.1590 - accuracy: 0.0132 - precision: 0.9483 - recall: 0.9483 - val_loss: 0.1814 - val_accuracy: 0.0367 - val_precision: 0.9477 - val_recall: 0.9477\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.1351 - accuracy: 0.0244 - precision: 0.9521 - recall: 0.9521 - val_loss: 0.1474 - val_accuracy: 0.0232 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.1305 - accuracy: 0.0221 - precision: 0.9581 - recall: 0.9581 - val_loss: 0.1390 - val_accuracy: 0.0117 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 1s 50us/sample - loss: 0.1203 - accuracy: 0.0390 - precision: 0.9619 - recall: 0.9619 - val_loss: 0.1502 - val_accuracy: 0.0544 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 1s 54us/sample - loss: 0.1160 - accuracy: 0.0542 - precision: 0.9602 - recall: 0.9602 - val_loss: 0.1383 - val_accuracy: 0.0560 - val_precision: 0.9642 - val_recall: 0.9642\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 1s 50us/sample - loss: 0.1106 - accuracy: 0.0759 - precision: 0.9641 - recall: 0.9641 - val_loss: 0.1554 - val_accuracy: 0.0850 - val_precision: 0.9536 - val_recall: 0.9536\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.1055 - accuracy: 0.0915 - precision: 0.9671 - recall: 0.9671 - val_loss: 0.1675 - val_accuracy: 0.0755 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 1s 49us/sample - loss: 0.1050 - accuracy: 0.1069 - precision: 0.9681 - recall: 0.9681 - val_loss: 0.2171 - val_accuracy: 0.0931 - val_precision: 0.9412 - val_recall: 0.9412\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.1063 - accuracy: 0.1157 - precision: 0.9683 - recall: 0.9683 - val_loss: 0.1383 - val_accuracy: 0.0772 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 1s 50us/sample - loss: 0.1031 - accuracy: 0.1322 - precision: 0.9700 - recall: 0.9700 - val_loss: 0.1553 - val_accuracy: 0.1118 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - 1s 49us/sample - loss: 0.0999 - accuracy: 0.1424 - precision: 0.9712 - recall: 0.9712 - val_loss: 0.1921 - val_accuracy: 0.1196 - val_precision: 0.9509 - val_recall: 0.9509\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 1s 51us/sample - loss: 0.0933 - accuracy: 0.1476 - precision: 0.9712 - recall: 0.9712 - val_loss: 0.2116 - val_accuracy: 0.1978 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - 1s 47us/sample - loss: 0.0974 - accuracy: 0.1807 - precision: 0.9723 - recall: 0.9723 - val_loss: 0.3173 - val_accuracy: 0.2283 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.1037 - accuracy: 0.2050 - precision: 0.9723 - recall: 0.9723 - val_loss: 0.1801 - val_accuracy: 0.1884 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0754 - accuracy: 0.2199 - precision: 0.9755 - recall: 0.9755 - val_loss: 0.2187 - val_accuracy: 0.2386 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0839 - accuracy: 0.2248 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.2029 - val_accuracy: 0.2145 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.0834 - accuracy: 0.2396 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.2203 - val_accuracy: 0.2583 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0836 - accuracy: 0.2600 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.2365 - val_accuracy: 0.2802 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0895 - accuracy: 0.2556 - precision: 0.9774 - recall: 0.9774 - val_loss: 0.1833 - val_accuracy: 0.1756 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 1s 44us/sample - loss: 0.0746 - accuracy: 0.2668 - precision: 0.9797 - recall: 0.9797 - val_loss: 0.2375 - val_accuracy: 0.2774 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0769 - accuracy: 0.3003 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.2132 - val_accuracy: 0.3248 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0706 - accuracy: 0.3073 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.2353 - val_accuracy: 0.3269 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0748 - accuracy: 0.3205 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.2418 - val_accuracy: 0.3458 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0746 - accuracy: 0.3324 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.2119 - val_accuracy: 0.3210 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0768 - accuracy: 0.3248 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.2533 - val_accuracy: 0.3204 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.0743 - accuracy: 0.3371 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.2394 - val_accuracy: 0.3102 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0729 - accuracy: 0.3448 - precision: 0.9823 - recall: 0.9823 - val_loss: 0.2958 - val_accuracy: 0.3622 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0811 - accuracy: 0.3589 - precision: 0.9819 - recall: 0.9819 - val_loss: 0.2614 - val_accuracy: 0.3434 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 1s 47us/sample - loss: 0.0695 - accuracy: 0.3581 - precision: 0.9844 - recall: 0.9844 - val_loss: 0.2598 - val_accuracy: 0.3411 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0777 - accuracy: 0.3660 - precision: 0.9830 - recall: 0.9830 - val_loss: 0.2795 - val_accuracy: 0.3529 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 1s 44us/sample - loss: 0.0772 - accuracy: 0.4005 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.3130 - val_accuracy: 0.4064 - val_precision: 0.9574 - val_recall: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0720 - accuracy: 0.3955 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.2694 - val_accuracy: 0.3890 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 1s 44us/sample - loss: 0.0759 - accuracy: 0.4095 - precision: 0.9851 - recall: 0.9851 - val_loss: 0.2610 - val_accuracy: 0.3862 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0734 - accuracy: 0.4245 - precision: 0.9859 - recall: 0.9859 - val_loss: 0.3063 - val_accuracy: 0.4554 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0726 - accuracy: 0.4195 - precision: 0.9838 - recall: 0.9838 - val_loss: 0.2943 - val_accuracy: 0.4336 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0635 - accuracy: 0.4141 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2386 - val_accuracy: 0.4060 - val_precision: 0.9654 - val_recall: 0.9654\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 1s 47us/sample - loss: 0.0667 - accuracy: 0.4294 - precision: 0.9866 - recall: 0.9866 - val_loss: 0.2983 - val_accuracy: 0.4091 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 39/60\n",
      "13526/13526 [==============================] - 1s 49us/sample - loss: 0.0654 - accuracy: 0.4401 - precision: 0.9844 - recall: 0.9844 - val_loss: 0.2859 - val_accuracy: 0.4166 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.0623 - accuracy: 0.4626 - precision: 0.9881 - recall: 0.9881 - val_loss: 0.3103 - val_accuracy: 0.4604 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.0656 - accuracy: 0.4519 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.2615 - val_accuracy: 0.3862 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0579 - accuracy: 0.4441 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.4308 - val_accuracy: 0.4556 - val_precision: 0.9483 - val_recall: 0.9483\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 1s 49us/sample - loss: 0.0784 - accuracy: 0.4567 - precision: 0.9868 - recall: 0.9868 - val_loss: 0.3848 - val_accuracy: 0.4579 - val_precision: 0.9536 - val_recall: 0.9536\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 1s 47us/sample - loss: 0.0577 - accuracy: 0.4677 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.3864 - val_accuracy: 0.5217 - val_precision: 0.9524 - val_recall: 0.9524\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0754 - accuracy: 0.4676 - precision: 0.9874 - recall: 0.9874 - val_loss: 0.3329 - val_accuracy: 0.4570 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 1s 49us/sample - loss: 0.0565 - accuracy: 0.4775 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.3745 - val_accuracy: 0.5047 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0634 - accuracy: 0.5034 - precision: 0.9883 - recall: 0.9883 - val_loss: 0.3263 - val_accuracy: 0.5052 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 1s 49us/sample - loss: 0.0669 - accuracy: 0.5096 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.3056 - val_accuracy: 0.4622 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 1s 47us/sample - loss: 0.0608 - accuracy: 0.5037 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.3635 - val_accuracy: 0.5105 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 1s 50us/sample - loss: 0.1285 - accuracy: 0.5060 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.3730 - val_accuracy: 0.4959 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 1s 50us/sample - loss: 0.1157 - accuracy: 0.5076 - precision: 0.9854 - recall: 0.9854 - val_loss: 0.3721 - val_accuracy: 0.5231 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.0881 - accuracy: 0.5256 - precision: 0.9868 - recall: 0.9868 - val_loss: 0.3630 - val_accuracy: 0.5043 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0735 - accuracy: 0.5232 - precision: 0.9896 - recall: 0.9896 - val_loss: 0.3552 - val_accuracy: 0.5214 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0569 - accuracy: 0.5258 - precision: 0.9900 - recall: 0.9900 - val_loss: 0.3566 - val_accuracy: 0.5299 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 1s 46us/sample - loss: 0.0583 - accuracy: 0.5476 - precision: 0.9902 - recall: 0.9902 - val_loss: 0.4167 - val_accuracy: 0.5454 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.0554 - accuracy: 0.5542 - precision: 0.9906 - recall: 0.9906 - val_loss: 0.4345 - val_accuracy: 0.5458 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 1s 48us/sample - loss: 0.0858 - accuracy: 0.5698 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.3659 - val_accuracy: 0.5448 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 1s 47us/sample - loss: 0.0630 - accuracy: 0.5579 - precision: 0.9898 - recall: 0.9898 - val_loss: 0.3780 - val_accuracy: 0.5538 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 1s 55us/sample - loss: 0.0600 - accuracy: 0.5648 - precision: 0.9909 - recall: 0.9909 - val_loss: 0.3508 - val_accuracy: 0.5829 - val_precision: 0.9642 - val_recall: 0.9642\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 1s 56us/sample - loss: 0.0840 - accuracy: 0.5779 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.2967 - val_accuracy: 0.5136 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 20)                1580      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,042\n",
      "Trainable params: 2,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 1s 38us/sample - loss: 0.2125 - accuracy: 2.5876e-04 - precision: 0.9200 - recall: 0.9200 - val_loss: 0.1744 - val_accuracy: 1.4784e-04 - val_precision: 0.9409 - val_recall: 0.9409\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.1353 - accuracy: 4.4359e-04 - precision: 0.9508 - recall: 0.9508 - val_loss: 0.1908 - val_accuracy: 0.0019 - val_precision: 0.9311 - val_recall: 0.9311\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1189 - accuracy: 9.6111e-04 - precision: 0.9556 - recall: 0.9556 - val_loss: 0.1299 - val_accuracy: 0.0010 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1114 - accuracy: 0.0011 - precision: 0.9590 - recall: 0.9590 - val_loss: 0.1412 - val_accuracy: 5.9137e-04 - val_precision: 0.9524 - val_recall: 0.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.1031 - accuracy: 0.0026 - precision: 0.9613 - recall: 0.9613 - val_loss: 0.1350 - val_accuracy: 0.0022 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.1011 - accuracy: 0.0023 - precision: 0.9643 - recall: 0.9643 - val_loss: 0.1141 - val_accuracy: 0.0019 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 0s 23us/sample - loss: 0.0940 - accuracy: 0.0028 - precision: 0.9655 - recall: 0.9655 - val_loss: 0.1243 - val_accuracy: 0.0022 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0912 - accuracy: 0.0043 - precision: 0.9664 - recall: 0.9664 - val_loss: 0.1164 - val_accuracy: 0.0075 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0891 - accuracy: 0.0040 - precision: 0.9678 - recall: 0.9678 - val_loss: 0.1225 - val_accuracy: 0.0027 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0855 - accuracy: 0.0055 - precision: 0.9673 - recall: 0.9673 - val_loss: 0.1153 - val_accuracy: 0.0049 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0816 - accuracy: 0.0069 - precision: 0.9706 - recall: 0.9706 - val_loss: 0.1226 - val_accuracy: 0.0049 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.0064 - precision: 0.9711 - recall: 0.971 - 0s 14us/sample - loss: 0.0794 - accuracy: 0.0063 - precision: 0.9709 - recall: 0.9709 - val_loss: 0.1301 - val_accuracy: 0.0041 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0785 - accuracy: 0.0076 - precision: 0.9706 - recall: 0.9706 - val_loss: 0.1209 - val_accuracy: 0.0030 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.0077 - precision: 0.9715 - recall: 0.9715 - 0s 18us/sample - loss: 0.0755 - accuracy: 0.0079 - precision: 0.9716 - recall: 0.9716 - val_loss: 0.1282 - val_accuracy: 0.0095 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0764 - accuracy: 0.0111 - precision: 0.9719 - recall: 0.9719 - val_loss: 0.1442 - val_accuracy: 0.0135 - val_precision: 0.9542 - val_recall: 0.9542\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0728 - accuracy: 0.0149 - precision: 0.9736 - recall: 0.9736 - val_loss: 0.1243 - val_accuracy: 0.0151 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0747 - accuracy: 0.0167 - precision: 0.9720 - recall: 0.9720 - val_loss: 0.1232 - val_accuracy: 0.0095 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0732 - accuracy: 0.0146 - precision: 0.9732 - recall: 0.9732 - val_loss: 0.1205 - val_accuracy: 0.0139 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0710 - accuracy: 0.0211 - precision: 0.9732 - recall: 0.9732 - val_loss: 0.1215 - val_accuracy: 0.0163 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0704 - accuracy: 0.0258 - precision: 0.9749 - recall: 0.9749 - val_loss: 0.1271 - val_accuracy: 0.0225 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0686 - accuracy: 0.0239 - precision: 0.9765 - recall: 0.9765 - val_loss: 0.1295 - val_accuracy: 0.0294 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0694 - accuracy: 0.0300 - precision: 0.9756 - recall: 0.9756 - val_loss: 0.1252 - val_accuracy: 0.0179 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0667 - accuracy: 0.0277 - precision: 0.9766 - recall: 0.9766 - val_loss: 0.1439 - val_accuracy: 0.0284 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0654 - accuracy: 0.0273 - precision: 0.9770 - recall: 0.9770 - val_loss: 0.1295 - val_accuracy: 0.0319 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0643 - accuracy: 0.0322 - precision: 0.9777 - recall: 0.9777 - val_loss: 0.1448 - val_accuracy: 0.0350 - val_precision: 0.9542 - val_recall: 0.9542\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0617 - accuracy: 0.0413 - precision: 0.9780 - recall: 0.9780 - val_loss: 0.1417 - val_accuracy: 0.0297 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0618 - accuracy: 0.0430 - precision: 0.9783 - recall: 0.9783 - val_loss: 0.1335 - val_accuracy: 0.0401 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0653 - accuracy: 0.0452 - precision: 0.9778 - recall: 0.9778 - val_loss: 0.1353 - val_accuracy: 0.0312 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0600 - accuracy: 0.0404 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1476 - val_accuracy: 0.0452 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0599 - accuracy: 0.0539 - precision: 0.9780 - recall: 0.9780 - val_loss: 0.1398 - val_accuracy: 0.0452 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0570 - accuracy: 0.0574 - precision: 0.9801 - recall: 0.9801 - val_loss: 0.1536 - val_accuracy: 0.0673 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0574 - accuracy: 0.0608 - precision: 0.9799 - recall: 0.9799 - val_loss: 0.1534 - val_accuracy: 0.0847 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0566 - accuracy: 0.0785 - precision: 0.9800 - recall: 0.9800 - val_loss: 0.1502 - val_accuracy: 0.0818 - val_precision: 0.9642 - val_recall: 0.9642\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 0s 14us/sample - loss: 0.0555 - accuracy: 0.0847 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.1607 - val_accuracy: 0.0871 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0544 - accuracy: 0.0843 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.1436 - val_accuracy: 0.0890 - val_precision: 0.9645 - val_recall: 0.9645\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0555 - accuracy: 0.0838 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1472 - val_accuracy: 0.0866 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0538 - accuracy: 0.0917 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.1702 - val_accuracy: 0.0927 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0531 - accuracy: 0.1025 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.1730 - val_accuracy: 0.1016 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 39/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0539 - accuracy: 0.1046 - precision: 0.9806 - recall: 0.9806 - val_loss: 0.1566 - val_accuracy: 0.1109 - val_precision: 0.9610 - val_recall: 0.9610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0526 - accuracy: 0.0950 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.1583 - val_accuracy: 0.1082 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0493 - accuracy: 0.1069 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.1550 - val_accuracy: 0.0988 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0526 - accuracy: 0.1106 - precision: 0.9823 - recall: 0.9823 - val_loss: 0.1435 - val_accuracy: 0.0940 - val_precision: 0.9645 - val_recall: 0.9645\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0494 - accuracy: 0.1068 - precision: 0.9817 - recall: 0.9817 - val_loss: 0.1729 - val_accuracy: 0.1168 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0493 - accuracy: 0.1178 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.1669 - val_accuracy: 0.1166 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 0s 11us/sample - loss: 0.0489 - accuracy: 0.1267 - precision: 0.9832 - recall: 0.9832 - val_loss: 0.1724 - val_accuracy: 0.1161 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0458 - accuracy: 0.1339 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.1778 - val_accuracy: 0.1577 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 0s 11us/sample - loss: 0.0494 - accuracy: 0.1445 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.1745 - val_accuracy: 0.1489 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0470 - accuracy: 0.1459 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.1797 - val_accuracy: 0.1502 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 0s 11us/sample - loss: 0.0452 - accuracy: 0.1516 - precision: 0.9834 - recall: 0.9834 - val_loss: 0.1875 - val_accuracy: 0.1705 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0458 - accuracy: 0.1634 - precision: 0.9847 - recall: 0.9847 - val_loss: 0.1848 - val_accuracy: 0.1416 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 0s 11us/sample - loss: 0.0437 - accuracy: 0.1643 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.1889 - val_accuracy: 0.1733 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0477 - accuracy: 0.1712 - precision: 0.9838 - recall: 0.9838 - val_loss: 0.1926 - val_accuracy: 0.1589 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0452 - accuracy: 0.1722 - precision: 0.9841 - recall: 0.9841 - val_loss: 0.2071 - val_accuracy: 0.1849 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0478 - accuracy: 0.1853 - precision: 0.9826 - recall: 0.9826 - val_loss: 0.1916 - val_accuracy: 0.1671 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0482 - accuracy: 0.1813 - precision: 0.9856 - recall: 0.9856 - val_loss: 0.1949 - val_accuracy: 0.1582 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0445 - accuracy: 0.1776 - precision: 0.9849 - recall: 0.9849 - val_loss: 0.1980 - val_accuracy: 0.1879 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0418 - accuracy: 0.1828 - precision: 0.9866 - recall: 0.9866 - val_loss: 0.2068 - val_accuracy: 0.1866 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0434 - accuracy: 0.1920 - precision: 0.9859 - recall: 0.9859 - val_loss: 0.1888 - val_accuracy: 0.1792 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 0s 13us/sample - loss: 0.0456 - accuracy: 0.1897 - precision: 0.9851 - recall: 0.9851 - val_loss: 0.2031 - val_accuracy: 0.1894 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 0s 12us/sample - loss: 0.0440 - accuracy: 0.1924 - precision: 0.9854 - recall: 0.9854 - val_loss: 0.2039 - val_accuracy: 0.1894 - val_precision: 0.9586 - val_recall: 0.9586\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Perceptron\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x, y, \"NN/PerceptronPlus\",0.005,60, [500,500,2]))\n",
    "results.append(executeNN(x, y, \"NN/PerceptronMoins\",0.005,60, [20,20,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/200\n",
      "13526/13526 [==============================] - 1s 42us/sample - loss: 0.1922 - accuracy: 0.0013 - precision: 0.9292 - recall: 0.9292 - val_loss: 0.1568 - val_accuracy: 0.0012 - val_precision: 0.9432 - val_recall: 0.9432\n",
      "Epoch 2/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.1326 - accuracy: 0.0017 - precision: 0.9533 - recall: 0.9533 - val_loss: 0.2051 - val_accuracy: 0.0019 - val_precision: 0.9169 - val_recall: 0.9169\n",
      "Epoch 3/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1160 - accuracy: 0.0037 - precision: 0.9601 - recall: 0.9601 - val_loss: 0.1571 - val_accuracy: 0.0064 - val_precision: 0.9488 - val_recall: 0.9488\n",
      "Epoch 4/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1091 - accuracy: 0.0055 - precision: 0.9624 - recall: 0.9624 - val_loss: 0.1552 - val_accuracy: 0.0087 - val_precision: 0.9491 - val_recall: 0.9491\n",
      "Epoch 5/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1022 - accuracy: 0.0079 - precision: 0.9641 - recall: 0.9641 - val_loss: 0.1541 - val_accuracy: 0.0022 - val_precision: 0.9456 - val_recall: 0.9456\n",
      "Epoch 6/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0989 - accuracy: 0.0146 - precision: 0.9654 - recall: 0.9654 - val_loss: 0.1344 - val_accuracy: 0.0234 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 7/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0939 - accuracy: 0.0217 - precision: 0.9677 - recall: 0.9677 - val_loss: 0.1237 - val_accuracy: 0.0035 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 8/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0864 - accuracy: 0.0247 - precision: 0.9697 - recall: 0.9697 - val_loss: 0.1355 - val_accuracy: 0.0392 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 9/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0831 - accuracy: 0.0388 - precision: 0.9720 - recall: 0.9720 - val_loss: 0.1663 - val_accuracy: 0.0603 - val_precision: 0.9524 - val_recall: 0.9524\n",
      "Epoch 10/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0736 - accuracy: 0.0490 - precision: 0.9732 - recall: 0.9732 - val_loss: 0.1437 - val_accuracy: 0.0559 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 11/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0746 - accuracy: 0.0586 - precision: 0.9740 - recall: 0.9740 - val_loss: 0.2122 - val_accuracy: 0.0494 - val_precision: 0.9216 - val_recall: 0.9216\n",
      "Epoch 12/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0724 - accuracy: 0.0722 - precision: 0.9756 - recall: 0.9756 - val_loss: 0.1456 - val_accuracy: 0.0764 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 13/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0679 - accuracy: 0.0889 - precision: 0.9755 - recall: 0.9755 - val_loss: 0.1560 - val_accuracy: 0.0936 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 14/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0669 - accuracy: 0.0995 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.1644 - val_accuracy: 0.1107 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 15/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0637 - accuracy: 0.1196 - precision: 0.9780 - recall: 0.9780 - val_loss: 0.1849 - val_accuracy: 0.1368 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 16/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0589 - accuracy: 0.1413 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1589 - val_accuracy: 0.1249 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 17/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0647 - accuracy: 0.1397 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.1878 - val_accuracy: 0.1743 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 18/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0606 - accuracy: 0.1679 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.1641 - val_accuracy: 0.1347 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 19/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0584 - accuracy: 0.1793 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.1682 - val_accuracy: 0.1339 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 20/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0528 - accuracy: 0.1937 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.2527 - val_accuracy: 0.2821 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 21/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0624 - accuracy: 0.1964 - precision: 0.9816 - recall: 0.9816 - val_loss: 0.1820 - val_accuracy: 0.1745 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 22/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0544 - accuracy: 0.2041 - precision: 0.9825 - recall: 0.9825 - val_loss: 0.1727 - val_accuracy: 0.1909 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 23/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0475 - accuracy: 0.2188 - precision: 0.9851 - recall: 0.9851 - val_loss: 0.1818 - val_accuracy: 0.2107 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 24/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0487 - accuracy: 0.2211 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.1960 - val_accuracy: 0.2235 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 25/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0500 - accuracy: 0.2404 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2018 - val_accuracy: 0.2561 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 26/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0440 - accuracy: 0.2578 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.2209 - val_accuracy: 0.2652 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 27/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0493 - accuracy: 0.2637 - precision: 0.9865 - recall: 0.9865 - val_loss: 0.2279 - val_accuracy: 0.3199 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 28/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0439 - accuracy: 0.2940 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.2277 - val_accuracy: 0.2778 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 29/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0493 - accuracy: 0.2967 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.2385 - val_accuracy: 0.2992 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 30/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0389 - accuracy: 0.3036 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.2359 - val_accuracy: 0.3213 - val_precision: 0.9642 - val_recall: 0.9642\n",
      "Epoch 31/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0433 - accuracy: 0.3225 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.2541 - val_accuracy: 0.2853 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 32/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0502 - accuracy: 0.3309 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.2430 - val_accuracy: 0.3155 - val_precision: 0.9604 - val_recall: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0451 - accuracy: 0.3416 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.2483 - val_accuracy: 0.3278 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 34/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0407 - accuracy: 0.3388 - precision: 0.9902 - recall: 0.9902 - val_loss: 0.2176 - val_accuracy: 0.2960 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 35/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0456 - accuracy: 0.3478 - precision: 0.9895 - recall: 0.9895 - val_loss: 0.2380 - val_accuracy: 0.3084 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 36/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0412 - accuracy: 0.3656 - precision: 0.9913 - recall: 0.9913 - val_loss: 0.2827 - val_accuracy: 0.3554 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 37/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0410 - accuracy: 0.3666 - precision: 0.9898 - recall: 0.9898 - val_loss: 0.2428 - val_accuracy: 0.3539 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 38/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0406 - accuracy: 0.3812 - precision: 0.9903 - recall: 0.9903 - val_loss: 0.2756 - val_accuracy: 0.3530 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 39/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0352 - accuracy: 0.3699 - precision: 0.9912 - recall: 0.9912 - val_loss: 0.2754 - val_accuracy: 0.3739 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 40/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0371 - accuracy: 0.3815 - precision: 0.9912 - recall: 0.9912 - val_loss: 0.2939 - val_accuracy: 0.3737 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 41/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0356 - accuracy: 0.3895 - precision: 0.9918 - recall: 0.9918 - val_loss: 0.3106 - val_accuracy: 0.3967 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 42/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0406 - accuracy: 0.4017 - precision: 0.9909 - recall: 0.9909 - val_loss: 0.3076 - val_accuracy: 0.3795 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 43/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0415 - accuracy: 0.3869 - precision: 0.9905 - recall: 0.9905 - val_loss: 0.2870 - val_accuracy: 0.3912 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 44/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0333 - accuracy: 0.3955 - precision: 0.9918 - recall: 0.9918 - val_loss: 0.3007 - val_accuracy: 0.3868 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 45/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0351 - accuracy: 0.3954 - precision: 0.9922 - recall: 0.9922 - val_loss: 0.2673 - val_accuracy: 0.3894 - val_precision: 0.9636 - val_recall: 0.9636\n",
      "Epoch 46/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0544 - accuracy: 0.4106 - precision: 0.9913 - recall: 0.9913 - val_loss: 0.3291 - val_accuracy: 0.4061 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 47/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0447 - accuracy: 0.4202 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.3177 - val_accuracy: 0.4247 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 48/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0466 - accuracy: 0.4192 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.3193 - val_accuracy: 0.4122 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 49/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0445 - accuracy: 0.4226 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.3167 - val_accuracy: 0.4092 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 50/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0411 - accuracy: 0.4227 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.4016 - val_accuracy: 0.3930 - val_precision: 0.9462 - val_recall: 0.9462\n",
      "Epoch 51/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0374 - accuracy: 0.4394 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.3174 - val_accuracy: 0.4126 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 52/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0337 - accuracy: 0.4317 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.3436 - val_accuracy: 0.4338 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 53/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0341 - accuracy: 0.4395 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.3116 - val_accuracy: 0.4313 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 54/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0348 - accuracy: 0.4360 - precision: 0.9928 - recall: 0.9928 - val_loss: 0.3471 - val_accuracy: 0.4329 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 55/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0303 - accuracy: 0.4532 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.3088 - val_accuracy: 0.4386 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 56/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0312 - accuracy: 0.4543 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.3282 - val_accuracy: 0.4418 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 57/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0309 - accuracy: 0.4572 - precision: 0.9924 - recall: 0.9924 - val_loss: 0.2988 - val_accuracy: 0.4373 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 58/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0367 - accuracy: 0.4688 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.3765 - val_accuracy: 0.4667 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 59/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0276 - accuracy: 0.4739 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.3346 - val_accuracy: 0.4858 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 60/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0294 - accuracy: 0.4751 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.3628 - val_accuracy: 0.4639 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 61/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0345 - accuracy: 0.4783 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.3826 - val_accuracy: 0.4752 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 62/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0348 - accuracy: 0.4692 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.3754 - val_accuracy: 0.4540 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 63/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0363 - accuracy: 0.4685 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.3322 - val_accuracy: 0.4401 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 64/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0238 - accuracy: 0.4756 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.3318 - val_accuracy: 0.4673 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 65/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0221 - accuracy: 0.4869 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.3788 - val_accuracy: 0.4719 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 66/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0257 - accuracy: 0.4966 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.3985 - val_accuracy: 0.4954 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 67/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0207 - accuracy: 0.5010 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.3773 - val_accuracy: 0.5067 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 68/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0224 - accuracy: 0.5026 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.3738 - val_accuracy: 0.4945 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 69/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0322 - accuracy: 0.5179 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.4197 - val_accuracy: 0.4795 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 70/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0242 - accuracy: 0.5148 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.4251 - val_accuracy: 0.4988 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 71/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0304 - accuracy: 0.5332 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.4029 - val_accuracy: 0.5055 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 72/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0260 - accuracy: 0.5146 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.3715 - val_accuracy: 0.5022 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 73/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0278 - accuracy: 0.5231 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.4114 - val_accuracy: 0.5238 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 74/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0250 - accuracy: 0.5335 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.4219 - val_accuracy: 0.4731 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 75/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0283 - accuracy: 0.5245 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.4182 - val_accuracy: 0.5021 - val_precision: 0.9524 - val_recall: 0.9524\n",
      "Epoch 76/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0329 - accuracy: 0.5292 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.3650 - val_accuracy: 0.4914 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 77/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0270 - accuracy: 0.5514 - precision: 0.9957 - recall: 0.9957 - val_loss: 0.4212 - val_accuracy: 0.5191 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 78/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0208 - accuracy: 0.5413 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.3991 - val_accuracy: 0.5449 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 79/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0275 - accuracy: 0.5551 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4137 - val_accuracy: 0.5466 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 80/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0352 - accuracy: 0.5564 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.4466 - val_accuracy: 0.5265 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 81/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0304 - accuracy: 0.5546 - precision: 0.9957 - recall: 0.9957 - val_loss: 0.3854 - val_accuracy: 0.5399 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 82/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0346 - accuracy: 0.5623 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.4247 - val_accuracy: 0.5340 - val_precision: 0.9542 - val_recall: 0.9542\n",
      "Epoch 83/200\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0330 - accuracy: 0.5679 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.3923 - val_accuracy: 0.5404 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 84/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0273 - accuracy: 0.5656 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4244 - val_accuracy: 0.5466 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 85/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0312 - accuracy: 0.5701 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.3713 - val_accuracy: 0.5392 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 86/200\n",
      "13526/13526 [==============================] - 0s 15us/sample - loss: 0.0245 - accuracy: 0.5715 - precision: 0.9955 - recall: 0.9955 - val_loss: 0.3797 - val_accuracy: 0.5664 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 87/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0324 - accuracy: 0.5779 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.4439 - val_accuracy: 0.5896 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 88/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0374 - accuracy: 0.5919 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.4201 - val_accuracy: 0.5736 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 89/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0318 - accuracy: 0.5973 - precision: 0.9955 - recall: 0.9955 - val_loss: 0.4000 - val_accuracy: 0.5721 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 90/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0366 - accuracy: 0.5855 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.4602 - val_accuracy: 0.5522 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 91/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0333 - accuracy: 0.5883 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.4229 - val_accuracy: 0.5640 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 92/200\n",
      "13526/13526 [==============================] - 0s 23us/sample - loss: 0.0401 - accuracy: 0.5830 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.4431 - val_accuracy: 0.5580 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 93/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0234 - accuracy: 0.5827 - precision: 0.9964 - recall: 0.9964 - val_loss: 0.4497 - val_accuracy: 0.5710 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 94/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0244 - accuracy: 0.6071 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.4258 - val_accuracy: 0.5822 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 95/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0300 - accuracy: 0.6076 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.4799 - val_accuracy: 0.5575 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 96/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0304 - accuracy: 0.6030 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4730 - val_accuracy: 0.5989 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 97/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0304 - accuracy: 0.6121 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.4106 - val_accuracy: 0.6014 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 98/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0294 - accuracy: 0.6253 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.4292 - val_accuracy: 0.5900 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 99/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0209 - accuracy: 0.6180 - precision: 0.9968 - recall: 0.9968 - val_loss: 0.4169 - val_accuracy: 0.5999 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 100/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0264 - accuracy: 0.6336 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.4433 - val_accuracy: 0.6336 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 101/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0225 - accuracy: 0.6309 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4793 - val_accuracy: 0.6189 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 102/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0210 - accuracy: 0.6384 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.4795 - val_accuracy: 0.5973 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0286 - accuracy: 0.6322 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.4445 - val_accuracy: 0.6245 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 104/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0261 - accuracy: 0.6517 - precision: 0.9957 - recall: 0.9957 - val_loss: 0.4564 - val_accuracy: 0.6322 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 105/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0372 - accuracy: 0.6361 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.4423 - val_accuracy: 0.6060 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 106/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0246 - accuracy: 0.6344 - precision: 0.9964 - recall: 0.9964 - val_loss: 0.4567 - val_accuracy: 0.6359 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 107/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0265 - accuracy: 0.6418 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.4647 - val_accuracy: 0.6081 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 108/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0258 - accuracy: 0.6177 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.4732 - val_accuracy: 0.5961 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 109/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0252 - accuracy: 0.6140 - precision: 0.9964 - recall: 0.9964 - val_loss: 0.4376 - val_accuracy: 0.5949 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 110/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0261 - accuracy: 0.6189 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.4471 - val_accuracy: 0.6044 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 111/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0323 - accuracy: 0.6229 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.4217 - val_accuracy: 0.6149 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 112/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0238 - accuracy: 0.6301 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.4381 - val_accuracy: 0.6353 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 113/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0211 - accuracy: 0.6461 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.4173 - val_accuracy: 0.6178 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 114/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0247 - accuracy: 0.6451 - precision: 0.9963 - recall: 0.9963 - val_loss: 0.4301 - val_accuracy: 0.6561 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 115/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0212 - accuracy: 0.6576 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.4736 - val_accuracy: 0.6110 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 116/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0307 - accuracy: 0.6572 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4485 - val_accuracy: 0.6387 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 117/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0420 - accuracy: 0.6531 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.4592 - val_accuracy: 0.6437 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 118/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0206 - accuracy: 0.6462 - precision: 0.9964 - recall: 0.9964 - val_loss: 0.4720 - val_accuracy: 0.6404 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 119/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0249 - accuracy: 0.6500 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.4752 - val_accuracy: 0.6481 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 120/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0211 - accuracy: 0.6638 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.4650 - val_accuracy: 0.6561 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 121/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0220 - accuracy: 0.6617 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.4669 - val_accuracy: 0.6282 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 122/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0181 - accuracy: 0.6741 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.4847 - val_accuracy: 0.6721 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 123/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0268 - accuracy: 0.6961 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.4704 - val_accuracy: 0.6796 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 124/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0210 - accuracy: 0.6963 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.4542 - val_accuracy: 0.6273 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 125/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0240 - accuracy: 0.6830 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.5339 - val_accuracy: 0.6815 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 126/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0298 - accuracy: 0.6810 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.4739 - val_accuracy: 0.6517 - val_precision: 0.9542 - val_recall: 0.9542\n",
      "Epoch 127/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0235 - accuracy: 0.6713 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4530 - val_accuracy: 0.6609 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 128/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0412 - accuracy: 0.6835 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.4364 - val_accuracy: 0.6594 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 129/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0238 - accuracy: 0.6761 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4896 - val_accuracy: 0.6378 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 130/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0209 - accuracy: 0.6851 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.4519 - val_accuracy: 0.6787 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 131/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0245 - accuracy: 0.6837 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4876 - val_accuracy: 0.6728 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 132/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0193 - accuracy: 0.6947 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.4748 - val_accuracy: 0.6740 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 133/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0238 - accuracy: 0.6906 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4390 - val_accuracy: 0.6740 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 134/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0262 - accuracy: 0.7001 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.4858 - val_accuracy: 0.6677 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 135/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0222 - accuracy: 0.7011 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.4833 - val_accuracy: 0.6773 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 136/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0336 - accuracy: 0.6860 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4665 - val_accuracy: 0.6860 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 137/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0274 - accuracy: 0.7007 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.5086 - val_accuracy: 0.6805 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 138/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0181 - accuracy: 0.6939 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.4545 - val_accuracy: 0.6462 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 139/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0239 - accuracy: 0.6997 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.5049 - val_accuracy: 0.6940 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 140/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0212 - accuracy: 0.7097 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.4834 - val_accuracy: 0.6866 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 141/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0272 - accuracy: 0.6957 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4960 - val_accuracy: 0.6688 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 142/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0318 - accuracy: 0.6865 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.4797 - val_accuracy: 0.7065 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 143/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0126 - accuracy: 0.7083 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.4645 - val_accuracy: 0.6953 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 144/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0170 - accuracy: 0.7248 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.5021 - val_accuracy: 0.6925 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 145/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0273 - accuracy: 0.7218 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.4890 - val_accuracy: 0.6944 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 146/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0196 - accuracy: 0.7197 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.4846 - val_accuracy: 0.7096 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 147/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0285 - accuracy: 0.7116 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.4912 - val_accuracy: 0.6635 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 148/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0270 - accuracy: 0.7087 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4906 - val_accuracy: 0.6839 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 149/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0234 - accuracy: 0.7100 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4715 - val_accuracy: 0.7074 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 150/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0316 - accuracy: 0.7265 - precision: 0.9963 - recall: 0.9963 - val_loss: 0.4834 - val_accuracy: 0.7135 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 151/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0228 - accuracy: 0.7203 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.4973 - val_accuracy: 0.6925 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 152/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0449 - accuracy: 0.7086 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.4580 - val_accuracy: 0.7082 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 153/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0177 - accuracy: 0.7289 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.4720 - val_accuracy: 0.6918 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 154/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0214 - accuracy: 0.7209 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.4645 - val_accuracy: 0.7014 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 155/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0224 - accuracy: 0.7203 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.5073 - val_accuracy: 0.7090 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 156/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0306 - accuracy: 0.7170 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.4768 - val_accuracy: 0.7061 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 157/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0172 - accuracy: 0.7259 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.4837 - val_accuracy: 0.7204 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 158/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0207 - accuracy: 0.7270 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.4825 - val_accuracy: 0.6937 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 159/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0224 - accuracy: 0.7305 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.4794 - val_accuracy: 0.7237 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 160/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0280 - accuracy: 0.7413 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.4866 - val_accuracy: 0.7201 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 161/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0199 - accuracy: 0.7124 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.5005 - val_accuracy: 0.7138 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 162/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0157 - accuracy: 0.7345 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.4722 - val_accuracy: 0.7204 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 163/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0186 - accuracy: 0.7463 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.4892 - val_accuracy: 0.7317 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 164/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0225 - accuracy: 0.7341 - precision: 0.9968 - recall: 0.9968 - val_loss: 0.5181 - val_accuracy: 0.7129 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 165/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0257 - accuracy: 0.7405 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.4946 - val_accuracy: 0.7166 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 166/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0139 - accuracy: 0.7364 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.5212 - val_accuracy: 0.7231 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 167/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0209 - accuracy: 0.7538 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.5218 - val_accuracy: 0.7235 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 168/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0206 - accuracy: 0.7469 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.5491 - val_accuracy: 0.7419 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 169/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0153 - accuracy: 0.7515 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.5309 - val_accuracy: 0.7221 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 170/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0198 - accuracy: 0.7223 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.5108 - val_accuracy: 0.6956 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 171/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0274 - accuracy: 0.7270 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.4971 - val_accuracy: 0.7292 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 172/200\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0215 - accuracy: 0.7351 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.5254 - val_accuracy: 0.7216 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0189 - accuracy: 0.7446 - precision: 0.9980 - recall: 0.9980 - val_loss: 0.5414 - val_accuracy: 0.7234 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 174/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0241 - accuracy: 0.7621 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.5113 - val_accuracy: 0.7475 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 175/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0374 - accuracy: 0.7595 - precision: 0.9963 - recall: 0.9963 - val_loss: 0.4990 - val_accuracy: 0.7244 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 176/200\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0270 - accuracy: 0.7449 - precision: 0.9963 - recall: 0.9963 - val_loss: 0.5020 - val_accuracy: 0.7167 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 177/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0218 - accuracy: 0.7424 - precision: 0.9975 - recall: 0.9975 - val_loss: 0.4822 - val_accuracy: 0.7277 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 178/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0228 - accuracy: 0.7446 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.4983 - val_accuracy: 0.6984 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 179/200\n",
      "13526/13526 [==============================] - 0s 23us/sample - loss: 0.0311 - accuracy: 0.7405 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.5318 - val_accuracy: 0.7136 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 180/200\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0236 - accuracy: 0.7280 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.5269 - val_accuracy: 0.7192 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 181/200\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0205 - accuracy: 0.7610 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.5544 - val_accuracy: 0.7284 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 182/200\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0203 - accuracy: 0.7535 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.5171 - val_accuracy: 0.7210 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 183/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0151 - accuracy: 0.7324 - precision: 0.9977 - recall: 0.9977 - val_loss: 0.4873 - val_accuracy: 0.6963 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 184/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0217 - accuracy: 0.7375 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.4953 - val_accuracy: 0.7256 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 185/200\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0117 - accuracy: 0.7518 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.4986 - val_accuracy: 0.7187 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 186/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0178 - accuracy: 0.7594 - precision: 0.9979 - recall: 0.9979 - val_loss: 0.4847 - val_accuracy: 0.7345 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 187/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0159 - accuracy: 0.7612 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.4794 - val_accuracy: 0.7388 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 188/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0328 - accuracy: 0.7639 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.5058 - val_accuracy: 0.7414 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 189/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0186 - accuracy: 0.7694 - precision: 0.9978 - recall: 0.9978 - val_loss: 0.5016 - val_accuracy: 0.7475 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 190/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0184 - accuracy: 0.7816 - precision: 0.9979 - recall: 0.9979 - val_loss: 0.5872 - val_accuracy: 0.7490 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 191/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0228 - accuracy: 0.7644 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.5061 - val_accuracy: 0.7402 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 192/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0213 - accuracy: 0.7701 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.4943 - val_accuracy: 0.7735 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 193/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0244 - accuracy: 0.7581 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.4795 - val_accuracy: 0.7448 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 194/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0112 - accuracy: 0.7642 - precision: 0.9987 - recall: 0.9987 - val_loss: 0.5419 - val_accuracy: 0.7312 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 195/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0206 - accuracy: 0.7719 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.4928 - val_accuracy: 0.7315 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 196/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0131 - accuracy: 0.7565 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.5158 - val_accuracy: 0.7572 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 197/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0230 - accuracy: 0.7793 - precision: 0.9971 - recall: 0.9971 - val_loss: 0.4933 - val_accuracy: 0.7364 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 198/200\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0160 - accuracy: 0.7611 - precision: 0.9979 - recall: 0.9979 - val_loss: 0.5213 - val_accuracy: 0.7277 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 199/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0087 - accuracy: 0.7664 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.4870 - val_accuracy: 0.7490 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 200/200\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0165 - accuracy: 0.7863 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.5022 - val_accuracy: 0.7926 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/20\n",
      "13526/13526 [==============================] - 1s 41us/sample - loss: 0.1844 - accuracy: 2.9573e-04 - precision: 0.9292 - recall: 0.9292 - val_loss: 0.1652 - val_accuracy: 2.9568e-04 - val_precision: 0.9406 - val_recall: 0.9406\n",
      "Epoch 2/20\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1277 - accuracy: 0.0021 - precision: 0.9526 - recall: 0.9526 - val_loss: 0.1174 - val_accuracy: 1.4784e-04 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 3/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1137 - accuracy: 0.0029 - precision: 0.9596 - recall: 0.9596 - val_loss: 0.1542 - val_accuracy: 0.0021 - val_precision: 0.9441 - val_recall: 0.9441\n",
      "Epoch 4/20\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.1051 - accuracy: 0.0057 - precision: 0.9604 - recall: 0.9604 - val_loss: 0.1359 - val_accuracy: 0.0200 - val_precision: 0.9622 - val_recall: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0987 - accuracy: 0.0076 - precision: 0.9664 - recall: 0.9664 - val_loss: 0.1338 - val_accuracy: 0.0129 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 6/20\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0944 - accuracy: 0.0157 - precision: 0.9658 - recall: 0.9658 - val_loss: 0.1351 - val_accuracy: 8.8705e-04 - val_precision: 0.9512 - val_recall: 0.9512\n",
      "Epoch 7/20\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0883 - accuracy: 0.0167 - precision: 0.9690 - recall: 0.9690 - val_loss: 0.1362 - val_accuracy: 0.0170 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 8/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0865 - accuracy: 0.0236 - precision: 0.9704 - recall: 0.9704 - val_loss: 0.1190 - val_accuracy: 0.0109 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 9/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0787 - accuracy: 0.0289 - precision: 0.9715 - recall: 0.9715 - val_loss: 0.1162 - val_accuracy: 0.0219 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "Epoch 10/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0735 - accuracy: 0.0475 - precision: 0.9743 - recall: 0.9743 - val_loss: 0.1362 - val_accuracy: 0.0550 - val_precision: 0.9648 - val_recall: 0.9648\n",
      "Epoch 11/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0724 - accuracy: 0.0502 - precision: 0.9742 - recall: 0.9742 - val_loss: 0.1532 - val_accuracy: 0.0939 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 12/20\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0694 - accuracy: 0.0808 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.1743 - val_accuracy: 0.0730 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 13/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0678 - accuracy: 0.0769 - precision: 0.9765 - recall: 0.9765 - val_loss: 0.1909 - val_accuracy: 0.1134 - val_precision: 0.9533 - val_recall: 0.9533\n",
      "Epoch 14/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0695 - accuracy: 0.1032 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.1603 - val_accuracy: 0.0844 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 15/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0644 - accuracy: 0.1129 - precision: 0.9793 - recall: 0.9793 - val_loss: 0.1625 - val_accuracy: 0.0983 - val_precision: 0.9530 - val_recall: 0.9530\n",
      "Epoch 16/20\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0620 - accuracy: 0.1344 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.1894 - val_accuracy: 0.1301 - val_precision: 0.9494 - val_recall: 0.9494\n",
      "Epoch 17/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0612 - accuracy: 0.1425 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.1666 - val_accuracy: 0.1394 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 18/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0596 - accuracy: 0.1648 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.1619 - val_accuracy: 0.1509 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 19/20\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0575 - accuracy: 0.1778 - precision: 0.9827 - recall: 0.9827 - val_loss: 0.2085 - val_accuracy: 0.1960 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 20/20\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0540 - accuracy: 0.1926 - precision: 0.9826 - recall: 0.9826 - val_loss: 0.2114 - val_accuracy: 0.2033 - val_precision: 0.9565 - val_recall: 0.9565\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Epoch\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x, y, \"NN/EpochPlus\",0.005,200, [100,100,2]))\n",
    "results.append(executeNN(x, y, \"NN/EpochMoins\",0.005,20, [100,100,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 1s 44us/sample - loss: 0.2163 - accuracy: 0.0012 - precision: 0.9243 - recall: 0.9243 - val_loss: 0.1948 - val_accuracy: 0.0024 - val_precision: 0.9391 - val_recall: 0.9391\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1398 - accuracy: 0.0059 - precision: 0.9496 - recall: 0.9496 - val_loss: 0.1713 - val_accuracy: 0.0071 - val_precision: 0.9376 - val_recall: 0.9376\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1308 - accuracy: 0.0073 - precision: 0.9527 - recall: 0.9527 - val_loss: 0.1693 - val_accuracy: 0.0148 - val_precision: 0.9494 - val_recall: 0.9494\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1244 - accuracy: 0.0105 - precision: 0.9585 - recall: 0.9585 - val_loss: 0.2082 - val_accuracy: 0.0166 - val_precision: 0.9293 - val_recall: 0.9293\n",
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1217 - accuracy: 0.0225 - precision: 0.9598 - recall: 0.9598 - val_loss: 0.1596 - val_accuracy: 0.0072 - val_precision: 0.9429 - val_recall: 0.9429\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.1104 - accuracy: 0.0250 - precision: 0.9605 - recall: 0.9605 - val_loss: 0.1341 - val_accuracy: 0.0231 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1060 - accuracy: 0.0404 - precision: 0.9640 - recall: 0.9640 - val_loss: 0.1685 - val_accuracy: 0.0782 - val_precision: 0.9518 - val_recall: 0.9518\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1058 - accuracy: 0.0451 - precision: 0.9655 - recall: 0.9655 - val_loss: 0.1395 - val_accuracy: 0.0106 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1048 - accuracy: 0.0648 - precision: 0.9670 - recall: 0.9670 - val_loss: 0.1883 - val_accuracy: 0.0982 - val_precision: 0.9456 - val_recall: 0.9456\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0996 - accuracy: 0.0958 - precision: 0.9671 - recall: 0.9671 - val_loss: 0.1550 - val_accuracy: 0.0693 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0941 - accuracy: 0.0752 - precision: 0.9685 - recall: 0.9685 - val_loss: 0.1493 - val_accuracy: 0.0970 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0888 - accuracy: 0.0827 - precision: 0.9711 - recall: 0.9711 - val_loss: 0.1505 - val_accuracy: 0.1248 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0893 - accuracy: 0.1096 - precision: 0.9704 - recall: 0.9704 - val_loss: 0.1871 - val_accuracy: 0.1490 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0878 - accuracy: 0.1142 - precision: 0.9726 - recall: 0.9726 - val_loss: 0.2407 - val_accuracy: 0.1730 - val_precision: 0.9503 - val_recall: 0.9503\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0891 - accuracy: 0.1300 - precision: 0.9728 - recall: 0.9728 - val_loss: 0.1590 - val_accuracy: 0.1091 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0799 - accuracy: 0.1426 - precision: 0.9730 - recall: 0.9730 - val_loss: 0.1880 - val_accuracy: 0.1774 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0858 - accuracy: 0.1681 - precision: 0.9755 - recall: 0.9755 - val_loss: 0.2236 - val_accuracy: 0.1354 - val_precision: 0.9465 - val_recall: 0.9465\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0887 - accuracy: 0.1760 - precision: 0.9736 - recall: 0.9736 - val_loss: 0.1812 - val_accuracy: 0.1861 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0905 - accuracy: 0.1842 - precision: 0.9745 - recall: 0.9745 - val_loss: 0.1967 - val_accuracy: 0.1820 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0817 - accuracy: 0.2047 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.1747 - val_accuracy: 0.1918 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0923 - accuracy: 0.2076 - precision: 0.9747 - recall: 0.9747 - val_loss: 0.1853 - val_accuracy: 0.1465 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1008 - accuracy: 0.2274 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.1828 - val_accuracy: 0.2201 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1085 - accuracy: 0.2297 - precision: 0.9755 - recall: 0.9755 - val_loss: 0.3545 - val_accuracy: 0.2085 - val_precision: 0.9423 - val_recall: 0.9423\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1015 - accuracy: 0.2485 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.2189 - val_accuracy: 0.2349 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0769 - accuracy: 0.2622 - precision: 0.9789 - recall: 0.9789 - val_loss: 0.2133 - val_accuracy: 0.2839 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0830 - accuracy: 0.2593 - precision: 0.9787 - recall: 0.9787 - val_loss: 0.2004 - val_accuracy: 0.2414 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0814 - accuracy: 0.2860 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.2254 - val_accuracy: 0.2645 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0804 - accuracy: 0.2805 - precision: 0.9803 - recall: 0.9803 - val_loss: 0.2200 - val_accuracy: 0.2085 - val_precision: 0.9536 - val_recall: 0.9536\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0676 - accuracy: 0.2866 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.2683 - val_accuracy: 0.3100 - val_precision: 0.9512 - val_recall: 0.9512\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0801 - accuracy: 0.2989 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.2239 - val_accuracy: 0.2768 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0736 - accuracy: 0.3193 - precision: 0.9829 - recall: 0.9829 - val_loss: 0.2549 - val_accuracy: 0.3111 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0793 - accuracy: 0.2919 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.2480 - val_accuracy: 0.2726 - val_precision: 0.9521 - val_recall: 0.9521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0705 - accuracy: 0.2949 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.2433 - val_accuracy: 0.3026 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0808 - accuracy: 0.3214 - precision: 0.9815 - recall: 0.9815 - val_loss: 0.2544 - val_accuracy: 0.3128 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0615 - accuracy: 0.3216 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.2732 - val_accuracy: 0.3216 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0720 - accuracy: 0.3450 - precision: 0.9830 - recall: 0.9830 - val_loss: 0.3323 - val_accuracy: 0.4110 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1024 - accuracy: 0.3446 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.2985 - val_accuracy: 0.3550 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0742 - accuracy: 0.3326 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.2535 - val_accuracy: 0.3653 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 39/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0881 - accuracy: 0.3715 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.2623 - val_accuracy: 0.3600 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0742 - accuracy: 0.3906 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.2843 - val_accuracy: 0.4030 - val_precision: 0.9571 - val_recall: 0.9571\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0645 - accuracy: 0.3802 - precision: 0.9844 - recall: 0.9844 - val_loss: 0.2537 - val_accuracy: 0.3547 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0950 - accuracy: 0.3974 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.3093 - val_accuracy: 0.4014 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.1047 - accuracy: 0.3834 - precision: 0.9824 - recall: 0.9824 - val_loss: 0.3018 - val_accuracy: 0.3717 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0546 - accuracy: 0.3914 - precision: 0.9862 - recall: 0.9862 - val_loss: 0.2712 - val_accuracy: 0.3974 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0567 - accuracy: 0.4265 - precision: 0.9878 - recall: 0.9878 - val_loss: 0.2824 - val_accuracy: 0.4558 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0508 - accuracy: 0.4352 - precision: 0.9875 - recall: 0.9875 - val_loss: 0.2921 - val_accuracy: 0.4314 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0527 - accuracy: 0.4415 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.3508 - val_accuracy: 0.4598 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0509 - accuracy: 0.4474 - precision: 0.9876 - recall: 0.9876 - val_loss: 0.2986 - val_accuracy: 0.4608 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0573 - accuracy: 0.4414 - precision: 0.9869 - recall: 0.9869 - val_loss: 0.3180 - val_accuracy: 0.4449 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0674 - accuracy: 0.4680 - precision: 0.9876 - recall: 0.9876 - val_loss: 0.2998 - val_accuracy: 0.4667 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0574 - accuracy: 0.4783 - precision: 0.9882 - recall: 0.9882 - val_loss: 0.3378 - val_accuracy: 0.4818 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.1487 - accuracy: 0.4653 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.3834 - val_accuracy: 0.4664 - val_precision: 0.9521 - val_recall: 0.9521\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0721 - accuracy: 0.4846 - precision: 0.9862 - recall: 0.9862 - val_loss: 0.3654 - val_accuracy: 0.4933 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0722 - accuracy: 0.4920 - precision: 0.9868 - recall: 0.9868 - val_loss: 0.3106 - val_accuracy: 0.4403 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1232 - accuracy: 0.4738 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.3836 - val_accuracy: 0.4897 - val_precision: 0.9524 - val_recall: 0.9524\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0650 - accuracy: 0.4936 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.3451 - val_accuracy: 0.4783 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0982 - accuracy: 0.4946 - precision: 0.9853 - recall: 0.9853 - val_loss: 0.3128 - val_accuracy: 0.4740 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0551 - accuracy: 0.5069 - precision: 0.9892 - recall: 0.9892 - val_loss: 0.3240 - val_accuracy: 0.4848 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0582 - accuracy: 0.5035 - precision: 0.9895 - recall: 0.9895 - val_loss: 0.3549 - val_accuracy: 0.4820 - val_precision: 0.9533 - val_recall: 0.9533\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0658 - accuracy: 0.5229 - precision: 0.9875 - recall: 0.9875 - val_loss: 0.3301 - val_accuracy: 0.5068 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13526 samples, validate on 3382 samples\n",
      "Epoch 1/60\n",
      "13526/13526 [==============================] - 1s 45us/sample - loss: 0.1775 - accuracy: 8.5021e-04 - precision: 0.9341 - recall: 0.9341 - val_loss: 0.1264 - val_accuracy: 2.9568e-04 - val_precision: 0.9554 - val_recall: 0.9554\n",
      "Epoch 2/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1216 - accuracy: 0.0011 - precision: 0.9579 - recall: 0.9579 - val_loss: 0.1377 - val_accuracy: 2.9568e-04 - val_precision: 0.9533 - val_recall: 0.9533\n",
      "Epoch 3/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.1123 - accuracy: 0.0022 - precision: 0.9613 - recall: 0.9613 - val_loss: 0.1464 - val_accuracy: 4.4352e-04 - val_precision: 0.9518 - val_recall: 0.9518\n",
      "Epoch 4/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.1026 - accuracy: 0.0024 - precision: 0.9648 - recall: 0.9648 - val_loss: 0.1687 - val_accuracy: 0.0016 - val_precision: 0.9539 - val_recall: 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0986 - accuracy: 0.0031 - precision: 0.9668 - recall: 0.9668 - val_loss: 0.1489 - val_accuracy: 0.0034 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 6/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0890 - accuracy: 0.0059 - precision: 0.9679 - recall: 0.9679 - val_loss: 0.1289 - val_accuracy: 0.0084 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 7/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0822 - accuracy: 0.0089 - precision: 0.9711 - recall: 0.9711 - val_loss: 0.1190 - val_accuracy: 0.0031 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 8/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0808 - accuracy: 0.0098 - precision: 0.9721 - recall: 0.9721 - val_loss: 0.1359 - val_accuracy: 0.0093 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 9/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0759 - accuracy: 0.0156 - precision: 0.9754 - recall: 0.9754 - val_loss: 0.1686 - val_accuracy: 0.0129 - val_precision: 0.9450 - val_recall: 0.9450\n",
      "Epoch 10/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0740 - accuracy: 0.0187 - precision: 0.9746 - recall: 0.9746 - val_loss: 0.1326 - val_accuracy: 0.0179 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 11/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0680 - accuracy: 0.0300 - precision: 0.9786 - recall: 0.9786 - val_loss: 0.1566 - val_accuracy: 0.0157 - val_precision: 0.9548 - val_recall: 0.9548\n",
      "Epoch 12/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0629 - accuracy: 0.0398 - precision: 0.9790 - recall: 0.9790 - val_loss: 0.1456 - val_accuracy: 0.0274 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 13/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0600 - accuracy: 0.0455 - precision: 0.9809 - recall: 0.9809 - val_loss: 0.1480 - val_accuracy: 0.0418 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 14/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0575 - accuracy: 0.0567 - precision: 0.9800 - recall: 0.9800 - val_loss: 0.1543 - val_accuracy: 0.0840 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 15/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0552 - accuracy: 0.0844 - precision: 0.9813 - recall: 0.9813 - val_loss: 0.1714 - val_accuracy: 0.0643 - val_precision: 0.9589 - val_recall: 0.9589\n",
      "Epoch 16/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0522 - accuracy: 0.0897 - precision: 0.9835 - recall: 0.9835 - val_loss: 0.1618 - val_accuracy: 0.0908 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 17/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0511 - accuracy: 0.1052 - precision: 0.9848 - recall: 0.9848 - val_loss: 0.1555 - val_accuracy: 0.0829 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 18/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0467 - accuracy: 0.1103 - precision: 0.9843 - recall: 0.9843 - val_loss: 0.1700 - val_accuracy: 0.1331 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 19/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0454 - accuracy: 0.1221 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.1884 - val_accuracy: 0.1579 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 20/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0433 - accuracy: 0.1446 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.1822 - val_accuracy: 0.1311 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 21/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0449 - accuracy: 0.1666 - precision: 0.9865 - recall: 0.9865 - val_loss: 0.1839 - val_accuracy: 0.1614 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 22/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0351 - accuracy: 0.1825 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.1960 - val_accuracy: 0.1833 - val_precision: 0.9627 - val_recall: 0.9627\n",
      "Epoch 23/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0394 - accuracy: 0.1804 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.2119 - val_accuracy: 0.2006 - val_precision: 0.9613 - val_recall: 0.9613\n",
      "Epoch 24/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0330 - accuracy: 0.2041 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2483 - val_accuracy: 0.1915 - val_precision: 0.9506 - val_recall: 0.9506\n",
      "Epoch 25/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0355 - accuracy: 0.2159 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.2083 - val_accuracy: 0.2323 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 26/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0365 - accuracy: 0.2267 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.2088 - val_accuracy: 0.2129 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 27/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0343 - accuracy: 0.2446 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.2301 - val_accuracy: 0.2493 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 28/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0311 - accuracy: 0.2570 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.2309 - val_accuracy: 0.2388 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 29/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0335 - accuracy: 0.2622 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.2232 - val_accuracy: 0.2490 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 30/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0341 - accuracy: 0.2644 - precision: 0.9913 - recall: 0.9913 - val_loss: 0.2498 - val_accuracy: 0.2513 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 31/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0335 - accuracy: 0.2638 - precision: 0.9906 - recall: 0.9906 - val_loss: 0.2345 - val_accuracy: 0.2893 - val_precision: 0.9619 - val_recall: 0.9619\n",
      "Epoch 32/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0297 - accuracy: 0.2753 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.2871 - val_accuracy: 0.2805 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 33/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0276 - accuracy: 0.2889 - precision: 0.9921 - recall: 0.9921 - val_loss: 0.2829 - val_accuracy: 0.2910 - val_precision: 0.9530 - val_recall: 0.9530\n",
      "Epoch 34/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0276 - accuracy: 0.3044 - precision: 0.9922 - recall: 0.9922 - val_loss: 0.2442 - val_accuracy: 0.2960 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 35/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0296 - accuracy: 0.3118 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.2599 - val_accuracy: 0.2870 - val_precision: 0.9542 - val_recall: 0.9542\n",
      "Epoch 36/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0254 - accuracy: 0.3168 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.2533 - val_accuracy: 0.3250 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 37/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0312 - accuracy: 0.3263 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.2840 - val_accuracy: 0.3470 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 38/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0267 - accuracy: 0.3304 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.3154 - val_accuracy: 0.3190 - val_precision: 0.9488 - val_recall: 0.9488\n",
      "Epoch 39/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0288 - accuracy: 0.3470 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.2778 - val_accuracy: 0.3584 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 40/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0257 - accuracy: 0.3458 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.2762 - val_accuracy: 0.3529 - val_precision: 0.9583 - val_recall: 0.9583\n",
      "Epoch 41/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0275 - accuracy: 0.3523 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.2804 - val_accuracy: 0.3536 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 42/60\n",
      "13526/13526 [==============================] - 0s 16us/sample - loss: 0.0246 - accuracy: 0.3573 - precision: 0.9943 - recall: 0.9943 - val_loss: 0.2870 - val_accuracy: 0.3272 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 43/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0226 - accuracy: 0.3517 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.2955 - val_accuracy: 0.3661 - val_precision: 0.9601 - val_recall: 0.9601\n",
      "Epoch 44/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0245 - accuracy: 0.3589 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.2946 - val_accuracy: 0.3479 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 45/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0287 - accuracy: 0.3653 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.2878 - val_accuracy: 0.3616 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 46/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0212 - accuracy: 0.3588 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.2844 - val_accuracy: 0.3631 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 47/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0230 - accuracy: 0.3741 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.3072 - val_accuracy: 0.3695 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 48/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0193 - accuracy: 0.3819 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.3245 - val_accuracy: 0.3641 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 49/60\n",
      "13526/13526 [==============================] - 0s 18us/sample - loss: 0.0246 - accuracy: 0.3823 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.3237 - val_accuracy: 0.3674 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 50/60\n",
      "13526/13526 [==============================] - 0s 17us/sample - loss: 0.0227 - accuracy: 0.3892 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.3452 - val_accuracy: 0.3891 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 51/60\n",
      "13526/13526 [==============================] - 0s 21us/sample - loss: 0.0249 - accuracy: 0.3916 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.2903 - val_accuracy: 0.3768 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 52/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0232 - accuracy: 0.3927 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.3313 - val_accuracy: 0.3952 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 53/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0270 - accuracy: 0.4008 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.3367 - val_accuracy: 0.3804 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 54/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0230 - accuracy: 0.3964 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.3522 - val_accuracy: 0.3832 - val_precision: 0.9565 - val_recall: 0.9565\n",
      "Epoch 55/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0254 - accuracy: 0.3983 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.3366 - val_accuracy: 0.3897 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 56/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0272 - accuracy: 0.4020 - precision: 0.9958 - recall: 0.9958 - val_loss: 0.3436 - val_accuracy: 0.4137 - val_precision: 0.9577 - val_recall: 0.9577\n",
      "Epoch 57/60\n",
      "13526/13526 [==============================] - 0s 22us/sample - loss: 0.0234 - accuracy: 0.4131 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.3681 - val_accuracy: 0.4262 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 58/60\n",
      "13526/13526 [==============================] - 0s 20us/sample - loss: 0.0214 - accuracy: 0.4192 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.3428 - val_accuracy: 0.4057 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 59/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0256 - accuracy: 0.4159 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.3291 - val_accuracy: 0.4073 - val_precision: 0.9624 - val_recall: 0.9624\n",
      "Epoch 60/60\n",
      "13526/13526 [==============================] - 0s 19us/sample - loss: 0.0272 - accuracy: 0.4195 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.3270 - val_accuracy: 0.4086 - val_precision: 0.9574 - val_recall: 0.9574\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" Learning rate\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x, y, \"NN/LearningRatePlus\",0.010,60, [100,100,2]))\n",
    "results.append(executeNN(x, y, \"NN/LearningRateMoins\",0.0025,60, [100,100,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10144 samples, validate on 2537 samples\n",
      "Epoch 1/60\n",
      "10144/10144 [==============================] - 1s 60us/sample - loss: 0.2034 - accuracy: 0.0017 - precision: 0.9264 - recall: 0.9264 - val_loss: 0.1585 - val_accuracy: 0.0020 - val_precision: 0.9448 - val_recall: 0.9448\n",
      "Epoch 2/60\n",
      "10144/10144 [==============================] - 0s 18us/sample - loss: 0.1328 - accuracy: 0.0016 - precision: 0.9515 - recall: 0.9515 - val_loss: 0.1467 - val_accuracy: 0.0014 - val_precision: 0.9547 - val_recall: 0.9547\n",
      "Epoch 3/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.1168 - accuracy: 0.0037 - precision: 0.9574 - recall: 0.9574 - val_loss: 0.1311 - val_accuracy: 0.0067 - val_precision: 0.9566 - val_recall: 0.9566\n",
      "Epoch 4/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.1102 - accuracy: 0.0066 - precision: 0.9605 - recall: 0.9605 - val_loss: 0.1494 - val_accuracy: 5.9125e-04 - val_precision: 0.9578 - val_recall: 0.9578\n",
      "Epoch 5/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0964 - accuracy: 0.0092 - precision: 0.9631 - recall: 0.9631 - val_loss: 0.1488 - val_accuracy: 0.0069 - val_precision: 0.9511 - val_recall: 0.9511\n",
      "Epoch 6/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0931 - accuracy: 0.0194 - precision: 0.9653 - recall: 0.9653 - val_loss: 0.1562 - val_accuracy: 0.0085 - val_precision: 0.9492 - val_recall: 0.9492\n",
      "Epoch 7/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0868 - accuracy: 0.0218 - precision: 0.9681 - recall: 0.9681 - val_loss: 0.2146 - val_accuracy: 0.0739 - val_precision: 0.9468 - val_recall: 0.9468\n",
      "Epoch 8/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0827 - accuracy: 0.0389 - precision: 0.9702 - recall: 0.9702 - val_loss: 0.1403 - val_accuracy: 0.0238 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 9/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0791 - accuracy: 0.0460 - precision: 0.9704 - recall: 0.9704 - val_loss: 0.1452 - val_accuracy: 0.0495 - val_precision: 0.9629 - val_recall: 0.9629\n",
      "Epoch 10/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0778 - accuracy: 0.0538 - precision: 0.9708 - recall: 0.9708 - val_loss: 0.1538 - val_accuracy: 0.0625 - val_precision: 0.9629 - val_recall: 0.9629\n",
      "Epoch 11/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0724 - accuracy: 0.0703 - precision: 0.9759 - recall: 0.9759 - val_loss: 0.1521 - val_accuracy: 0.0637 - val_precision: 0.9602 - val_recall: 0.9602\n",
      "Epoch 12/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0662 - accuracy: 0.0878 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.1616 - val_accuracy: 0.1054 - val_precision: 0.9653 - val_recall: 0.9653\n",
      "Epoch 13/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0636 - accuracy: 0.0989 - precision: 0.9781 - recall: 0.9781 - val_loss: 0.1920 - val_accuracy: 0.1145 - val_precision: 0.9566 - val_recall: 0.9566\n",
      "Epoch 14/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0598 - accuracy: 0.1041 - precision: 0.9776 - recall: 0.9776 - val_loss: 0.1696 - val_accuracy: 0.1462 - val_precision: 0.9618 - val_recall: 0.9618\n",
      "Epoch 15/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0629 - accuracy: 0.1309 - precision: 0.9793 - recall: 0.9793 - val_loss: 0.1562 - val_accuracy: 0.1082 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 16/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0537 - accuracy: 0.1520 - precision: 0.9807 - recall: 0.9807 - val_loss: 0.1651 - val_accuracy: 0.0757 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 17/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0536 - accuracy: 0.1447 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.1697 - val_accuracy: 0.1494 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 18/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0530 - accuracy: 0.1722 - precision: 0.9825 - recall: 0.9825 - val_loss: 0.2551 - val_accuracy: 0.1914 - val_precision: 0.9488 - val_recall: 0.9488\n",
      "Epoch 19/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0477 - accuracy: 0.2097 - precision: 0.9836 - recall: 0.9836 - val_loss: 0.2566 - val_accuracy: 0.1839 - val_precision: 0.9519 - val_recall: 0.9519\n",
      "Epoch 20/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0587 - accuracy: 0.1988 - precision: 0.9820 - recall: 0.9820 - val_loss: 0.2379 - val_accuracy: 0.2134 - val_precision: 0.9523 - val_recall: 0.9523\n",
      "Epoch 21/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0443 - accuracy: 0.2239 - precision: 0.9838 - recall: 0.9838 - val_loss: 0.1843 - val_accuracy: 0.1941 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 22/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0448 - accuracy: 0.2338 - precision: 0.9849 - recall: 0.9849 - val_loss: 0.2028 - val_accuracy: 0.2440 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 23/60\n",
      "10144/10144 [==============================] - 0s 16us/sample - loss: 0.0418 - accuracy: 0.2514 - precision: 0.9850 - recall: 0.9850 - val_loss: 0.1941 - val_accuracy: 0.2300 - val_precision: 0.9602 - val_recall: 0.9602\n",
      "Epoch 24/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0437 - accuracy: 0.2551 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.2160 - val_accuracy: 0.2491 - val_precision: 0.9602 - val_recall: 0.9602\n",
      "Epoch 25/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0416 - accuracy: 0.2582 - precision: 0.9865 - recall: 0.9865 - val_loss: 0.2028 - val_accuracy: 0.2722 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 26/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0379 - accuracy: 0.2853 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.2405 - val_accuracy: 0.3181 - val_precision: 0.9594 - val_recall: 0.9594\n",
      "Epoch 27/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0398 - accuracy: 0.2971 - precision: 0.9872 - recall: 0.9872 - val_loss: 0.2319 - val_accuracy: 0.2816 - val_precision: 0.9555 - val_recall: 0.9555\n",
      "Epoch 28/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0368 - accuracy: 0.2944 - precision: 0.9896 - recall: 0.9896 - val_loss: 0.2118 - val_accuracy: 0.2909 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 29/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0373 - accuracy: 0.3088 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2704 - val_accuracy: 0.3007 - val_precision: 0.9559 - val_recall: 0.9559\n",
      "Epoch 30/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0382 - accuracy: 0.3273 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.3353 - val_accuracy: 0.3258 - val_precision: 0.9448 - val_recall: 0.9448\n",
      "Epoch 31/60\n",
      "10144/10144 [==============================] - 0s 21us/sample - loss: 0.0431 - accuracy: 0.3260 - precision: 0.9893 - recall: 0.9893 - val_loss: 0.3458 - val_accuracy: 0.3238 - val_precision: 0.9507 - val_recall: 0.9507\n",
      "Epoch 32/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0400 - accuracy: 0.3414 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.3171 - val_accuracy: 0.3207 - val_precision: 0.9503 - val_recall: 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      "10144/10144 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.3445 - precision: 0.9907 - recall: 0.990 - 0s 23us/sample - loss: 0.0363 - accuracy: 0.3428 - precision: 0.9912 - recall: 0.9912 - val_loss: 0.2316 - val_accuracy: 0.3457 - val_precision: 0.9606 - val_recall: 0.9606\n",
      "Epoch 34/60\n",
      "10144/10144 [==============================] - 0s 24us/sample - loss: 0.0331 - accuracy: 0.3475 - precision: 0.9895 - recall: 0.9895 - val_loss: 0.2621 - val_accuracy: 0.3390 - val_precision: 0.9566 - val_recall: 0.9566\n",
      "Epoch 35/60\n",
      "10144/10144 [==============================] - 0s 24us/sample - loss: 0.0316 - accuracy: 0.3526 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.2912 - val_accuracy: 0.3674 - val_precision: 0.9582 - val_recall: 0.9582\n",
      "Epoch 36/60\n",
      "10144/10144 [==============================] - 0s 21us/sample - loss: 0.0318 - accuracy: 0.3627 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.2581 - val_accuracy: 0.3814 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 37/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0332 - accuracy: 0.3697 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.2620 - val_accuracy: 0.3591 - val_precision: 0.9606 - val_recall: 0.9606\n",
      "Epoch 38/60\n",
      "10144/10144 [==============================] - 0s 18us/sample - loss: 0.0484 - accuracy: 0.3777 - precision: 0.9900 - recall: 0.9900 - val_loss: 0.2731 - val_accuracy: 0.3695 - val_precision: 0.9594 - val_recall: 0.9594\n",
      "Epoch 39/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0278 - accuracy: 0.3854 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.2533 - val_accuracy: 0.3959 - val_precision: 0.9618 - val_recall: 0.9618\n",
      "Epoch 40/60\n",
      "10144/10144 [==============================] - 0s 18us/sample - loss: 0.0303 - accuracy: 0.3873 - precision: 0.9918 - recall: 0.9918 - val_loss: 0.2943 - val_accuracy: 0.4038 - val_precision: 0.9582 - val_recall: 0.9582\n",
      "Epoch 41/60\n",
      "10144/10144 [==============================] - 0s 20us/sample - loss: 0.0351 - accuracy: 0.3931 - precision: 0.9921 - recall: 0.9921 - val_loss: 0.3732 - val_accuracy: 0.3849 - val_precision: 0.9507 - val_recall: 0.9507\n",
      "Epoch 42/60\n",
      "10144/10144 [==============================] - 0s 20us/sample - loss: 0.0425 - accuracy: 0.3917 - precision: 0.9915 - recall: 0.9915 - val_loss: 0.3173 - val_accuracy: 0.3957 - val_precision: 0.9590 - val_recall: 0.9590\n",
      "Epoch 43/60\n",
      "10144/10144 [==============================] - 0s 22us/sample - loss: 0.0333 - accuracy: 0.4056 - precision: 0.9918 - recall: 0.9918 - val_loss: 0.2858 - val_accuracy: 0.3961 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 44/60\n",
      "10144/10144 [==============================] - 0s 20us/sample - loss: 0.0304 - accuracy: 0.4042 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.3018 - val_accuracy: 0.4093 - val_precision: 0.9606 - val_recall: 0.9606\n",
      "Epoch 45/60\n",
      "10144/10144 [==============================] - 0s 22us/sample - loss: 0.0301 - accuracy: 0.4184 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.3005 - val_accuracy: 0.4178 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 46/60\n",
      "10144/10144 [==============================] - 0s 21us/sample - loss: 0.0324 - accuracy: 0.4393 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.2963 - val_accuracy: 0.4383 - val_precision: 0.9590 - val_recall: 0.9590\n",
      "Epoch 47/60\n",
      "10144/10144 [==============================] - 0s 21us/sample - loss: 0.0321 - accuracy: 0.4361 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.3131 - val_accuracy: 0.4137 - val_precision: 0.9590 - val_recall: 0.9590\n",
      "Epoch 48/60\n",
      "10144/10144 [==============================] - 0s 20us/sample - loss: 0.0376 - accuracy: 0.4306 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.3926 - val_accuracy: 0.4330 - val_precision: 0.9535 - val_recall: 0.9535\n",
      "Epoch 49/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0373 - accuracy: 0.4334 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.3315 - val_accuracy: 0.4078 - val_precision: 0.9531 - val_recall: 0.9531\n",
      "Epoch 50/60\n",
      "10144/10144 [==============================] - 0s 17us/sample - loss: 0.0228 - accuracy: 0.4344 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.3003 - val_accuracy: 0.4539 - val_precision: 0.9633 - val_recall: 0.9633\n",
      "Epoch 51/60\n",
      "10144/10144 [==============================] - 0s 18us/sample - loss: 0.0265 - accuracy: 0.4503 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.3308 - val_accuracy: 0.4505 - val_precision: 0.9590 - val_recall: 0.9590\n",
      "Epoch 52/60\n",
      "10144/10144 [==============================] - 0s 18us/sample - loss: 0.0274 - accuracy: 0.4452 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.3188 - val_accuracy: 0.4395 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 53/60\n",
      "10144/10144 [==============================] - 0s 20us/sample - loss: 0.0178 - accuracy: 0.4563 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.2887 - val_accuracy: 0.4635 - val_precision: 0.9645 - val_recall: 0.9645\n",
      "Epoch 54/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0236 - accuracy: 0.4675 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.3377 - val_accuracy: 0.4492 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 55/60\n",
      "10144/10144 [==============================] - 0s 18us/sample - loss: 0.0241 - accuracy: 0.4751 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.3394 - val_accuracy: 0.4661 - val_precision: 0.9594 - val_recall: 0.9594\n",
      "Epoch 56/60\n",
      "10144/10144 [==============================] - 0s 20us/sample - loss: 0.0262 - accuracy: 0.4834 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.3143 - val_accuracy: 0.4831 - val_precision: 0.9606 - val_recall: 0.9606\n",
      "Epoch 57/60\n",
      "10144/10144 [==============================] - 0s 22us/sample - loss: 0.0288 - accuracy: 0.4888 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.3194 - val_accuracy: 0.4547 - val_precision: 0.9590 - val_recall: 0.9590\n",
      "Epoch 58/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0234 - accuracy: 0.4850 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.3181 - val_accuracy: 0.4947 - val_precision: 0.9618 - val_recall: 0.9618\n",
      "Epoch 59/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0306 - accuracy: 0.4883 - precision: 0.9943 - recall: 0.9943 - val_loss: 0.3443 - val_accuracy: 0.4846 - val_precision: 0.9566 - val_recall: 0.9566\n",
      "Epoch 60/60\n",
      "10144/10144 [==============================] - 0s 19us/sample - loss: 0.0186 - accuracy: 0.4944 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.3528 - val_accuracy: 0.4762 - val_precision: 0.9555 - val_recall: 0.9555\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" BaseLine75\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x[:int(len(x)*0.75)], y[:int(len(y)*0.75)], \"NN/BaseLine75\",0.005,60, [100,100,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6763 samples, validate on 1691 samples\n",
      "Epoch 1/60\n",
      "6763/6763 [==============================] - 1s 78us/sample - loss: 0.2278 - accuracy: 1.4786e-04 - precision: 0.9141 - recall: 0.9141 - val_loss: 0.1491 - val_accuracy: 0.0000e+00 - val_precision: 0.9462 - val_recall: 0.9462\n",
      "Epoch 2/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.1459 - accuracy: 2.2180e-04 - precision: 0.9460 - recall: 0.9460 - val_loss: 0.1720 - val_accuracy: 0.0000e+00 - val_precision: 0.9261 - val_recall: 0.9261\n",
      "Epoch 3/60\n",
      "6763/6763 [==============================] - 0s 17us/sample - loss: 0.1277 - accuracy: 0.0016 - precision: 0.9545 - recall: 0.9545 - val_loss: 0.1252 - val_accuracy: 0.0018 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 4/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.1132 - accuracy: 0.0027 - precision: 0.9589 - recall: 0.9589 - val_loss: 0.1167 - val_accuracy: 8.8705e-04 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 5/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.1070 - accuracy: 0.0030 - precision: 0.9627 - recall: 0.9627 - val_loss: 0.1169 - val_accuracy: 0.0012 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 6/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0952 - accuracy: 0.0062 - precision: 0.9636 - recall: 0.9636 - val_loss: 0.1494 - val_accuracy: 0.0071 - val_precision: 0.9462 - val_recall: 0.9462\n",
      "Epoch 7/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0888 - accuracy: 0.0117 - precision: 0.9666 - recall: 0.9666 - val_loss: 0.1258 - val_accuracy: 0.0098 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 8/60\n",
      "6763/6763 [==============================] - 0s 24us/sample - loss: 0.0824 - accuracy: 0.0144 - precision: 0.9688 - recall: 0.9688 - val_loss: 0.1275 - val_accuracy: 0.0068 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 9/60\n",
      "6763/6763 [==============================] - 0s 23us/sample - loss: 0.0797 - accuracy: 0.0235 - precision: 0.9707 - recall: 0.9707 - val_loss: 0.1342 - val_accuracy: 0.0287 - val_precision: 0.9562 - val_recall: 0.9562\n",
      "Epoch 10/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0709 - accuracy: 0.0402 - precision: 0.9735 - recall: 0.9735 - val_loss: 0.1738 - val_accuracy: 0.0831 - val_precision: 0.9497 - val_recall: 0.9497\n",
      "Epoch 11/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0708 - accuracy: 0.0450 - precision: 0.9734 - recall: 0.9734 - val_loss: 0.1422 - val_accuracy: 0.0302 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 12/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0621 - accuracy: 0.0546 - precision: 0.9790 - recall: 0.9790 - val_loss: 0.1197 - val_accuracy: 0.0568 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 13/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0664 - accuracy: 0.0691 - precision: 0.9774 - recall: 0.9774 - val_loss: 0.1474 - val_accuracy: 0.0816 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 14/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0657 - accuracy: 0.0827 - precision: 0.9805 - recall: 0.9805 - val_loss: 0.1317 - val_accuracy: 0.0970 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 15/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0563 - accuracy: 0.1062 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.1260 - val_accuracy: 0.0976 - val_precision: 0.9663 - val_recall: 0.9663\n",
      "Epoch 16/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0558 - accuracy: 0.1394 - precision: 0.9823 - recall: 0.9823 - val_loss: 0.2135 - val_accuracy: 0.1005 - val_precision: 0.9403 - val_recall: 0.9403\n",
      "Epoch 17/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0532 - accuracy: 0.1567 - precision: 0.9852 - recall: 0.9852 - val_loss: 0.1734 - val_accuracy: 0.1165 - val_precision: 0.9480 - val_recall: 0.9480\n",
      "Epoch 18/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0548 - accuracy: 0.1624 - precision: 0.9823 - recall: 0.9823 - val_loss: 0.1607 - val_accuracy: 0.1523 - val_precision: 0.9545 - val_recall: 0.9545\n",
      "Epoch 19/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0477 - accuracy: 0.1774 - precision: 0.9848 - recall: 0.9848 - val_loss: 0.1875 - val_accuracy: 0.1783 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 20/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.0481 - accuracy: 0.1863 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.1453 - val_accuracy: 0.1821 - val_precision: 0.9645 - val_recall: 0.9645\n",
      "Epoch 21/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0435 - accuracy: 0.2106 - precision: 0.9870 - recall: 0.9870 - val_loss: 0.1704 - val_accuracy: 0.1943 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 22/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0427 - accuracy: 0.2226 - precision: 0.9876 - recall: 0.9876 - val_loss: 0.2211 - val_accuracy: 0.2306 - val_precision: 0.9556 - val_recall: 0.9556\n",
      "Epoch 23/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0417 - accuracy: 0.2474 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.2044 - val_accuracy: 0.2519 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 24/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0459 - accuracy: 0.2609 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.1959 - val_accuracy: 0.2351 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 25/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0441 - accuracy: 0.2726 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.1785 - val_accuracy: 0.2407 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 26/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0374 - accuracy: 0.2743 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.1913 - val_accuracy: 0.2587 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 27/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0386 - accuracy: 0.2861 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.2684 - val_accuracy: 0.2537 - val_precision: 0.9486 - val_recall: 0.9486\n",
      "Epoch 28/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.0403 - accuracy: 0.2935 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.1958 - val_accuracy: 0.2661 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 29/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0305 - accuracy: 0.2991 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.1954 - val_accuracy: 0.2865 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 30/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0282 - accuracy: 0.3048 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.2344 - val_accuracy: 0.3019 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 31/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0299 - accuracy: 0.3215 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.2110 - val_accuracy: 0.3125 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 32/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0344 - accuracy: 0.3226 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.2239 - val_accuracy: 0.3025 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 33/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0294 - accuracy: 0.3339 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.2406 - val_accuracy: 0.3601 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 34/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0323 - accuracy: 0.3415 - precision: 0.9919 - recall: 0.9919 - val_loss: 0.2222 - val_accuracy: 0.3350 - val_precision: 0.9598 - val_recall: 0.9598\n",
      "Epoch 35/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.0299 - accuracy: 0.3404 - precision: 0.9925 - recall: 0.9925 - val_loss: 0.2423 - val_accuracy: 0.3409 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 36/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0335 - accuracy: 0.3481 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.2253 - val_accuracy: 0.3279 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 37/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0251 - accuracy: 0.3425 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.3031 - val_accuracy: 0.3933 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 38/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0235 - accuracy: 0.3782 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.2402 - val_accuracy: 0.3752 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 39/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0288 - accuracy: 0.3593 - precision: 0.9931 - recall: 0.9931 - val_loss: 0.2384 - val_accuracy: 0.3454 - val_precision: 0.9616 - val_recall: 0.9616\n",
      "Epoch 40/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.0201 - accuracy: 0.3705 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.2526 - val_accuracy: 0.3865 - val_precision: 0.9639 - val_recall: 0.9639\n",
      "Epoch 41/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0309 - accuracy: 0.3772 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.2692 - val_accuracy: 0.3779 - val_precision: 0.9586 - val_recall: 0.9586\n",
      "Epoch 42/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.0236 - accuracy: 0.3635 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.2367 - val_accuracy: 0.3755 - val_precision: 0.9651 - val_recall: 0.9651\n",
      "Epoch 43/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0325 - accuracy: 0.3842 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.2637 - val_accuracy: 0.3711 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 44/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0306 - accuracy: 0.3930 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.2506 - val_accuracy: 0.3965 - val_precision: 0.9681 - val_recall: 0.9681\n",
      "Epoch 45/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0200 - accuracy: 0.3920 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.3708 - val_accuracy: 0.3906 - val_precision: 0.9497 - val_recall: 0.9497\n",
      "Epoch 46/60\n",
      "6763/6763 [==============================] - 0s 19us/sample - loss: 0.0309 - accuracy: 0.3943 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.2439 - val_accuracy: 0.4083 - val_precision: 0.9669 - val_recall: 0.9669\n",
      "Epoch 47/60\n",
      "6763/6763 [==============================] - 0s 17us/sample - loss: 0.0256 - accuracy: 0.4053 - precision: 0.9945 - recall: 0.9945 - val_loss: 0.2258 - val_accuracy: 0.3873 - val_precision: 0.9645 - val_recall: 0.9645\n",
      "Epoch 48/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0205 - accuracy: 0.4156 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.3295 - val_accuracy: 0.3785 - val_precision: 0.9497 - val_recall: 0.9497\n",
      "Epoch 49/60\n",
      "6763/6763 [==============================] - 0s 23us/sample - loss: 0.0155 - accuracy: 0.4208 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.2392 - val_accuracy: 0.3986 - val_precision: 0.9651 - val_recall: 0.9651\n",
      "Epoch 50/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0322 - accuracy: 0.4300 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.2575 - val_accuracy: 0.4024 - val_precision: 0.9592 - val_recall: 0.9592\n",
      "Epoch 51/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0201 - accuracy: 0.4203 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.2909 - val_accuracy: 0.3906 - val_precision: 0.9533 - val_recall: 0.9533\n",
      "Epoch 52/60\n",
      "6763/6763 [==============================] - 0s 23us/sample - loss: 0.0242 - accuracy: 0.4233 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.2729 - val_accuracy: 0.4066 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 53/60\n",
      "6763/6763 [==============================] - 0s 22us/sample - loss: 0.0231 - accuracy: 0.4307 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.2759 - val_accuracy: 0.4284 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 54/60\n",
      "6763/6763 [==============================] - 0s 20us/sample - loss: 0.0240 - accuracy: 0.4395 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.3118 - val_accuracy: 0.3980 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 55/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0229 - accuracy: 0.4307 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.3084 - val_accuracy: 0.4089 - val_precision: 0.9580 - val_recall: 0.9580\n",
      "Epoch 56/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0169 - accuracy: 0.4455 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.2813 - val_accuracy: 0.4394 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 57/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0378 - accuracy: 0.4443 - precision: 0.9933 - recall: 0.9933 - val_loss: 0.2938 - val_accuracy: 0.4104 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 58/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0190 - accuracy: 0.4320 - precision: 0.9963 - recall: 0.9963 - val_loss: 0.3081 - val_accuracy: 0.4293 - val_precision: 0.9568 - val_recall: 0.9568\n",
      "Epoch 59/60\n",
      "6763/6763 [==============================] - 0s 18us/sample - loss: 0.0279 - accuracy: 0.4366 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.2726 - val_accuracy: 0.4293 - val_precision: 0.9604 - val_recall: 0.9604\n",
      "Epoch 60/60\n",
      "6763/6763 [==============================] - 0s 21us/sample - loss: 0.0225 - accuracy: 0.4480 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.2991 - val_accuracy: 0.4456 - val_precision: 0.9592 - val_recall: 0.9592\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" BaseLine50\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x[:int(len(x)*0.50)], y[:int(len(y)*0.50)], \"NN/BaseLine50\",0.005,60, [100,100,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 100)               7900      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 18,202\n",
      "Trainable params: 18,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3381 samples, validate on 846 samples\n",
      "Epoch 1/60\n",
      "3381/3381 [==============================] - 1s 157us/sample - loss: 0.2841 - accuracy: 2.9577e-04 - precision: 0.8991 - recall: 0.8991 - val_loss: 0.1717 - val_accuracy: 0.0012 - val_precision: 0.9326 - val_recall: 0.9326\n",
      "Epoch 2/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.1668 - accuracy: 1.4789e-04 - precision: 0.9394 - recall: 0.9394 - val_loss: 0.1817 - val_accuracy: 0.0012 - val_precision: 0.9362 - val_recall: 0.9362\n",
      "Epoch 3/60\n",
      "3381/3381 [==============================] - 0s 20us/sample - loss: 0.1415 - accuracy: 5.9154e-04 - precision: 0.9488 - recall: 0.9488 - val_loss: 0.2554 - val_accuracy: 0.0018 - val_precision: 0.9066 - val_recall: 0.9066\n",
      "Epoch 4/60\n",
      "3381/3381 [==============================] - 0s 19us/sample - loss: 0.1370 - accuracy: 0.0013 - precision: 0.9506 - recall: 0.9506 - val_loss: 0.1632 - val_accuracy: 0.0018 - val_precision: 0.9397 - val_recall: 0.9397\n",
      "Epoch 5/60\n",
      "3381/3381 [==============================] - 0s 22us/sample - loss: 0.1205 - accuracy: 0.0024 - precision: 0.9550 - recall: 0.9550 - val_loss: 0.2172 - val_accuracy: 0.0018 - val_precision: 0.9255 - val_recall: 0.9255\n",
      "Epoch 6/60\n",
      "3381/3381 [==============================] - 0s 25us/sample - loss: 0.1076 - accuracy: 0.0034 - precision: 0.9607 - recall: 0.9607 - val_loss: 0.1639 - val_accuracy: 0.0035 - val_precision: 0.9421 - val_recall: 0.9421\n",
      "Epoch 7/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.1042 - accuracy: 0.0046 - precision: 0.9592 - recall: 0.9592 - val_loss: 0.1393 - val_accuracy: 0.0047 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 8/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.0812 - accuracy: 0.0123 - precision: 0.9719 - recall: 0.9719 - val_loss: 0.1907 - val_accuracy: 0.0154 - val_precision: 0.9409 - val_recall: 0.9409\n",
      "Epoch 9/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.0934 - accuracy: 0.0143 - precision: 0.9660 - recall: 0.9660 - val_loss: 0.1413 - val_accuracy: 0.0071 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 10/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.0791 - accuracy: 0.0213 - precision: 0.9728 - recall: 0.9728 - val_loss: 0.1647 - val_accuracy: 0.0130 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 11/60\n",
      "3381/3381 [==============================] - 0s 29us/sample - loss: 0.0696 - accuracy: 0.0260 - precision: 0.9731 - recall: 0.9731 - val_loss: 0.1646 - val_accuracy: 0.0195 - val_precision: 0.9492 - val_recall: 0.9492\n",
      "Epoch 12/60\n",
      "3381/3381 [==============================] - 0s 25us/sample - loss: 0.0670 - accuracy: 0.0398 - precision: 0.9763 - recall: 0.9763 - val_loss: 0.1994 - val_accuracy: 0.0183 - val_precision: 0.9303 - val_recall: 0.9303\n",
      "Epoch 13/60\n",
      "3381/3381 [==============================] - 0s 22us/sample - loss: 0.0763 - accuracy: 0.0426 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.1607 - val_accuracy: 0.0384 - val_precision: 0.9504 - val_recall: 0.9504\n",
      "Epoch 14/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.0546 - accuracy: 0.0531 - precision: 0.9811 - recall: 0.9811 - val_loss: 0.2375 - val_accuracy: 0.0691 - val_precision: 0.9279 - val_recall: 0.9279\n",
      "Epoch 15/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.0497 - accuracy: 0.0664 - precision: 0.9796 - recall: 0.9796 - val_loss: 0.1972 - val_accuracy: 0.1164 - val_precision: 0.9492 - val_recall: 0.9492\n",
      "Epoch 16/60\n",
      "3381/3381 [==============================] - 0s 23us/sample - loss: 0.0510 - accuracy: 0.0822 - precision: 0.9781 - recall: 0.9781 - val_loss: 0.1964 - val_accuracy: 0.0626 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 17/60\n",
      "3381/3381 [==============================] - 0s 22us/sample - loss: 0.0498 - accuracy: 0.1080 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.1952 - val_accuracy: 0.0987 - val_precision: 0.9504 - val_recall: 0.9504\n",
      "Epoch 18/60\n",
      "3381/3381 [==============================] - 0s 21us/sample - loss: 0.0446 - accuracy: 0.1244 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.2304 - val_accuracy: 0.1531 - val_precision: 0.9480 - val_recall: 0.9480\n",
      "Epoch 19/60\n",
      "3381/3381 [==============================] - 0s 22us/sample - loss: 0.0559 - accuracy: 0.1365 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.2600 - val_accuracy: 0.1271 - val_precision: 0.9350 - val_recall: 0.9350\n",
      "Epoch 20/60\n",
      "3381/3381 [==============================] - 0s 22us/sample - loss: 0.0365 - accuracy: 0.1479 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.1721 - val_accuracy: 0.1418 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 21/60\n",
      "3381/3381 [==============================] - 0s 19us/sample - loss: 0.0496 - accuracy: 0.1818 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.1850 - val_accuracy: 0.1673 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 22/60\n",
      "3381/3381 [==============================] - 0s 19us/sample - loss: 0.0316 - accuracy: 0.2017 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.1934 - val_accuracy: 0.1678 - val_precision: 0.9480 - val_recall: 0.9480\n",
      "Epoch 23/60\n",
      "3381/3381 [==============================] - 0s 19us/sample - loss: 0.0308 - accuracy: 0.2118 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.2164 - val_accuracy: 0.2057 - val_precision: 0.9480 - val_recall: 0.9480\n",
      "Epoch 24/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0367 - accuracy: 0.2279 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.1925 - val_accuracy: 0.1986 - val_precision: 0.9563 - val_recall: 0.9563\n",
      "Epoch 25/60\n",
      "3381/3381 [==============================] - 0s 20us/sample - loss: 0.0294 - accuracy: 0.2560 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.3916 - val_accuracy: 0.2080 - val_precision: 0.9338 - val_recall: 0.9338\n",
      "Epoch 26/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0260 - accuracy: 0.2524 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.2287 - val_accuracy: 0.2535 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 27/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0314 - accuracy: 0.2706 - precision: 0.9908 - recall: 0.9908 - val_loss: 0.2263 - val_accuracy: 0.2571 - val_precision: 0.9574 - val_recall: 0.9574\n",
      "Epoch 28/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0119 - accuracy: 0.2776 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.2751 - val_accuracy: 0.2772 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 29/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0258 - accuracy: 0.2760 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.2811 - val_accuracy: 0.2914 - val_precision: 0.9492 - val_recall: 0.9492\n",
      "Epoch 30/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0281 - accuracy: 0.2993 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.2790 - val_accuracy: 0.2861 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 31/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0309 - accuracy: 0.3080 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.3013 - val_accuracy: 0.3316 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 32/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0242 - accuracy: 0.3231 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.5961 - val_accuracy: 0.1909 - val_precision: 0.8983 - val_recall: 0.8983\n",
      "Epoch 33/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0628 - accuracy: 0.2903 - precision: 0.9873 - recall: 0.9873 - val_loss: 0.2679 - val_accuracy: 0.2979 - val_precision: 0.9504 - val_recall: 0.9504\n",
      "Epoch 34/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0187 - accuracy: 0.3119 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.2468 - val_accuracy: 0.3351 - val_precision: 0.9563 - val_recall: 0.9563\n",
      "Epoch 35/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0272 - accuracy: 0.3282 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.2479 - val_accuracy: 0.3357 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 36/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0237 - accuracy: 0.3339 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.2343 - val_accuracy: 0.3150 - val_precision: 0.9622 - val_recall: 0.9622\n",
      "Epoch 37/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0139 - accuracy: 0.3330 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.3316 - val_accuracy: 0.3534 - val_precision: 0.9504 - val_recall: 0.9504\n",
      "Epoch 38/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0259 - accuracy: 0.3224 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.2935 - val_accuracy: 0.3292 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 39/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0209 - accuracy: 0.3496 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.3795 - val_accuracy: 0.3505 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 40/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0203 - accuracy: 0.3512 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.3172 - val_accuracy: 0.3357 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 41/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0432 - accuracy: 0.3477 - precision: 0.9905 - recall: 0.9905 - val_loss: 0.3170 - val_accuracy: 0.3558 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 42/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0157 - accuracy: 0.3716 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.3460 - val_accuracy: 0.3599 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 43/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0290 - accuracy: 0.3790 - precision: 0.9938 - recall: 0.9938 - val_loss: 0.3649 - val_accuracy: 0.3599 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 44/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0240 - accuracy: 0.3666 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.3298 - val_accuracy: 0.3469 - val_precision: 0.9504 - val_recall: 0.9504\n",
      "Epoch 45/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0157 - accuracy: 0.3702 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.3368 - val_accuracy: 0.3777 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 46/60\n",
      "3381/3381 [==============================] - 0s 16us/sample - loss: 0.0282 - accuracy: 0.3826 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.9791 - val_accuracy: 0.3073 - val_precision: 0.8889 - val_recall: 0.8889\n",
      "Epoch 47/60\n",
      "3381/3381 [==============================] - 0s 16us/sample - loss: 0.0239 - accuracy: 0.3789 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.3560 - val_accuracy: 0.3723 - val_precision: 0.9492 - val_recall: 0.9492\n",
      "Epoch 48/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0393 - accuracy: 0.3833 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.3513 - val_accuracy: 0.3735 - val_precision: 0.9492 - val_recall: 0.9492\n",
      "Epoch 49/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0297 - accuracy: 0.3823 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.3646 - val_accuracy: 0.3635 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 50/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0291 - accuracy: 0.3935 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3619 - val_accuracy: 0.3794 - val_precision: 0.9504 - val_recall: 0.9504\n",
      "Epoch 51/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0140 - accuracy: 0.3925 - precision: 0.9982 - recall: 0.9982 - val_loss: 0.3446 - val_accuracy: 0.3836 - val_precision: 0.9551 - val_recall: 0.9551\n",
      "Epoch 52/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0172 - accuracy: 0.3987 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.3499 - val_accuracy: 0.3877 - val_precision: 0.9527 - val_recall: 0.9527\n",
      "Epoch 53/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0159 - accuracy: 0.4185 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.4290 - val_accuracy: 0.3889 - val_precision: 0.9456 - val_recall: 0.9456\n",
      "Epoch 54/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0202 - accuracy: 0.4136 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.3645 - val_accuracy: 0.4019 - val_precision: 0.9563 - val_recall: 0.9563\n",
      "Epoch 55/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0120 - accuracy: 0.4091 - precision: 0.9979 - recall: 0.9979 - val_loss: 0.3448 - val_accuracy: 0.4019 - val_precision: 0.9515 - val_recall: 0.9515\n",
      "Epoch 56/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0221 - accuracy: 0.4096 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.3046 - val_accuracy: 0.3936 - val_precision: 0.9610 - val_recall: 0.9610\n",
      "Epoch 57/60\n",
      "3381/3381 [==============================] - 0s 20us/sample - loss: 0.0113 - accuracy: 0.4292 - precision: 0.9973 - recall: 0.9973 - val_loss: 0.3644 - val_accuracy: 0.4084 - val_precision: 0.9539 - val_recall: 0.9539\n",
      "Epoch 58/60\n",
      "3381/3381 [==============================] - 0s 18us/sample - loss: 0.0165 - accuracy: 0.4346 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.3220 - val_accuracy: 0.4202 - val_precision: 0.9634 - val_recall: 0.9634\n",
      "Epoch 59/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0373 - accuracy: 0.4320 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.3840 - val_accuracy: 0.3771 - val_precision: 0.9421 - val_recall: 0.9421\n",
      "Epoch 60/60\n",
      "3381/3381 [==============================] - 0s 17us/sample - loss: 0.0327 - accuracy: 0.4049 - precision: 0.9962 - recall: 0.9962 - val_loss: 0.4483 - val_accuracy: 0.4078 - val_precision: 0.9492 - val_recall: 0.9492\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\" BaseLine25\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "results.append(executeNN(x[:int(len(x)*0.25)], y[:int(len(y)*0.25)], \"NN/BaseLine25\",0.005,60, [100,100,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>NN/BaseLine</td>\n",
       "      <td>NN/CouchePlus</td>\n",
       "      <td>NN/CoucheMoins</td>\n",
       "      <td>NN/PerceptronPlus</td>\n",
       "      <td>NN/PerceptronMoins</td>\n",
       "      <td>NN/EpochPlus</td>\n",
       "      <td>NN/EpochMoins</td>\n",
       "      <td>NN/LearningRatePlus</td>\n",
       "      <td>NN/LearningRateMoins</td>\n",
       "      <td>NN/BaseLine75</td>\n",
       "      <td>NN/BaseLine50</td>\n",
       "      <td>NN/BaseLine25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time (seconds)</th>\n",
       "      <td>13.5398</td>\n",
       "      <td>18.1906</td>\n",
       "      <td>11.9895</td>\n",
       "      <td>40.1523</td>\n",
       "      <td>13.3691</td>\n",
       "      <td>48.2944</td>\n",
       "      <td>6.86552</td>\n",
       "      <td>16.4337</td>\n",
       "      <td>17.8652</td>\n",
       "      <td>14.6324</td>\n",
       "      <td>11.6123</td>\n",
       "      <td>7.92001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning rate</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.487579</td>\n",
       "      <td>0.778316</td>\n",
       "      <td>0.263308</td>\n",
       "      <td>0.577924</td>\n",
       "      <td>0.192407</td>\n",
       "      <td>0.786337</td>\n",
       "      <td>0.192555</td>\n",
       "      <td>0.522919</td>\n",
       "      <td>0.419451</td>\n",
       "      <td>0.494381</td>\n",
       "      <td>0.448026</td>\n",
       "      <td>0.40491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_accuracy</th>\n",
       "      <td>0.48906</td>\n",
       "      <td>0.763601</td>\n",
       "      <td>0.266115</td>\n",
       "      <td>0.513601</td>\n",
       "      <td>0.189385</td>\n",
       "      <td>0.792578</td>\n",
       "      <td>0.203282</td>\n",
       "      <td>0.506801</td>\n",
       "      <td>0.408634</td>\n",
       "      <td>0.476153</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>0.407801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.993494</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.988023</td>\n",
       "      <td>0.985362</td>\n",
       "      <td>0.998226</td>\n",
       "      <td>0.982626</td>\n",
       "      <td>0.987506</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.99517</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>0.996155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_f1</th>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.95683</td>\n",
       "      <td>0.961266</td>\n",
       "      <td>0.958604</td>\n",
       "      <td>0.962448</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>0.958013</td>\n",
       "      <td>0.957422</td>\n",
       "      <td>0.955459</td>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.949173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer: 0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer: 1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer: 2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer: 3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer: 4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0              1               2   \\\n",
       "run_name              NN/BaseLine  NN/CouchePlus  NN/CoucheMoins   \n",
       "train_time (seconds)      13.5398        18.1906         11.9895   \n",
       "learning rate               0.005          0.005           0.005   \n",
       "epoch                          60             60              60   \n",
       "accuracy                 0.487579       0.778316        0.263308   \n",
       "val_accuracy              0.48906       0.763601        0.266115   \n",
       "f1                       0.993494       0.988171        0.989502   \n",
       "val_f1                   0.959196       0.959196         0.95683   \n",
       "layer: 0                      100            100             100   \n",
       "layer: 1                      100            100               2   \n",
       "layer: 2                        2            100             NaN   \n",
       "layer: 3                      NaN            100             NaN   \n",
       "layer: 4                      NaN              2             NaN   \n",
       "\n",
       "                                     3                   4             5   \\\n",
       "run_name              NN/PerceptronPlus  NN/PerceptronMoins  NN/EpochPlus   \n",
       "train_time (seconds)            40.1523             13.3691       48.2944   \n",
       "learning rate                     0.005               0.005         0.005   \n",
       "epoch                                60                  60           200   \n",
       "accuracy                       0.577924            0.192407      0.786337   \n",
       "val_accuracy                   0.513601            0.189385      0.792578   \n",
       "f1                             0.988023            0.985362      0.998226   \n",
       "val_f1                         0.961266            0.958604      0.962448   \n",
       "layer: 0                            500                  20           100   \n",
       "layer: 1                            500                  20           100   \n",
       "layer: 2                              2                   2             2   \n",
       "layer: 3                            NaN                 NaN           NaN   \n",
       "layer: 4                            NaN                 NaN           NaN   \n",
       "\n",
       "                                 6                    7   \\\n",
       "run_name              NN/EpochMoins  NN/LearningRatePlus   \n",
       "train_time (seconds)        6.86552              16.4337   \n",
       "learning rate                 0.005                 0.01   \n",
       "epoch                            20                   60   \n",
       "accuracy                   0.192555             0.522919   \n",
       "val_accuracy               0.203282             0.506801   \n",
       "f1                         0.982626             0.987506   \n",
       "val_f1                     0.956535             0.958013   \n",
       "layer: 0                        100                  100   \n",
       "layer: 1                        100                  100   \n",
       "layer: 2                          2                    2   \n",
       "layer: 3                        NaN                  NaN   \n",
       "layer: 4                        NaN                  NaN   \n",
       "\n",
       "                                        8              9              10  \\\n",
       "run_name              NN/LearningRateMoins  NN/BaseLine75  NN/BaseLine50   \n",
       "train_time (seconds)               17.8652        14.6324        11.6123   \n",
       "learning rate                       0.0025          0.005          0.005   \n",
       "epoch                                   60             60             60   \n",
       "accuracy                          0.419451       0.494381       0.448026   \n",
       "val_accuracy                      0.408634       0.476153       0.445594   \n",
       "f1                                0.995194        0.99517       0.996008   \n",
       "val_f1                            0.957422       0.955459       0.959196   \n",
       "layer: 0                               100            100            100   \n",
       "layer: 1                               100            100            100   \n",
       "layer: 2                                 2              2              2   \n",
       "layer: 3                               NaN            NaN            NaN   \n",
       "layer: 4                               NaN            NaN            NaN   \n",
       "\n",
       "                                 11  \n",
       "run_name              NN/BaseLine25  \n",
       "train_time (seconds)        7.92001  \n",
       "learning rate                 0.005  \n",
       "epoch                            60  \n",
       "accuracy                    0.40491  \n",
       "val_accuracy               0.407801  \n",
       "f1                         0.996155  \n",
       "val_f1                     0.949173  \n",
       "layer: 0                        100  \n",
       "layer: 1                        100  \n",
       "layer: 2                          2  \n",
       "layer: 3                        NaN  \n",
       "layer: 4                        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(results).transpose())\n",
    "pd.DataFrame(results).transpose().to_pickle(\"NNResult.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
